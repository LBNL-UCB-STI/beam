{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7b5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Create a summary table of more scenarios\n",
    "#2) Create a summary of the summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60917bae-9d99-42f8-b03e-f296010ceac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /opt/conda/lib/python3.9/site-packages (from geopandas) (3.3.1)\n",
      "Requirement already satisfied: shapely<2,>=1.7 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.2)\n",
      "Requirement already satisfied: fiona>=1.8 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.21)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.4.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (8.1.2)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (61.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->geopandas) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->geopandas) (3.0.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pygeos in /opt/conda/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.9/site-packages (from pygeos) (1.21.5)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.9/site-packages (2.49.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.9/site-packages (2022.5.0)\n",
      "Requirement already satisfied: fsspec==2022.5.0 in /opt/conda/lib/python3.9/site-packages (from s3fs) (2022.5.0)\n",
      "Requirement already satisfied: aiobotocore~=2.3.0 in /opt/conda/lib/python3.9/site-packages (from s3fs) (2.3.4)\n",
      "Requirement already satisfied: aiohttp<=4 in /opt/conda/lib/python3.9/site-packages (from s3fs) (3.8.1)\n",
      "Requirement already satisfied: botocore<1.24.22,>=1.24.21 in /opt/conda/lib/python3.9/site-packages (from aiobotocore~=2.3.0->s3fs) (1.24.21)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.9/site-packages (from aiobotocore~=2.3.0->s3fs) (0.10.0)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.9/site-packages (from aiobotocore~=2.3.0->s3fs) (1.14.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (2.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<=4->s3fs) (1.7.2)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.9/site-packages (from aioitertools>=0.5.1->aiobotocore~=2.3.0->s3fs) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs) (2.8.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs) (1.26.9)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs) (1.16.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.9/site-packages (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n",
    "! pip install pandas\n",
    "! pip install pygeos\n",
    "! pip install boto\n",
    "! pip install s3fs\n",
    "! pip install shapely\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import time\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1aa1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs filepath, data_names, names\n",
    "\n",
    "nrows = None #None for all rows\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#############NYC##############\n",
    "fp = \"s3://beam-outputs/output/newyork/\"\n",
    "output_nm = 'SummaryTable_NYC.csv'\n",
    "len_id_transit = 10\n",
    "fp_res = 'outputs/'\n",
    "is_NYC = True\n",
    "is_WC = False\n",
    "data_names = [\n",
    "              # 'new-york-split_scenario-part-1__2022-06-03_17-21-39_iqs/ITERS/it.0/0.events.csv.gz', \n",
    "              # 'new-york-split_scenario-part-2__2022-06-15_14-26-18_cuu/ITERS/it.0/0.events.csv.gz', \n",
    "              # 'new-york-split_scenario-part-3__2022-06-15_14-26-18_dmi/ITERS/it.0/0.events.csv.gz',\n",
    "              'new-york-300k-calibration-7__2022-06-25_17-40-03_aui/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-11__2022-06-28_21-55-14_hbf/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-12__2022-06-28_21-54-34_tav/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-13__2022-06-29_17-21-34_psu/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-15__2022-06-30_15-57-54_zqu/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-16__2022-07-04_14-46-10_wvt/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-300k-calibration-17__2022-07-05_20-44-02_ccs/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-450k-calibration-18__2022-07-08_15-39-57_pxy/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-450k-calibration-19__2022-07-12_17-14-44_esm/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-450k-calibration-20__2022-07-12_22-31-28_czx/ITERS/it.10/10.events.csv.gz',\n",
    "              # 'new-york-baseline-0-of-10__2022-07-17_01-19-13_fgz/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-3-of-10__2022-07-17_01-19-21_soy/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-4-of-10__2022-07-17_01-19-20_qig/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-5-of-10__2022-07-17_01-19-12_yyt/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-6-of-10__2022-07-17_01-19-12_dgi/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-7-of-10__2022-07-17_01-19-14_qip/ITERS/it.5/5.events.csv.gz',\n",
    "              # 'new-york-baseline-8-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.events.csv.gz'\n",
    "#               'new-york-baseline-2-of-10__2022-07-19_01-38-47_ryr/ITERS/it.0/0.events.csv.gz',\n",
    "#               'new-york-baseline-9-of-10__2022-07-19_01-38-46_hfm/ITERS/it.0/0.events.csv.gz',\n",
    "#               'new-york-baseline-1-of-10__2022-07-19_15-06-02_ewc/ITERS/it.0/0.events.csv.gz'\n",
    "            ]\n",
    "\n",
    "plan_names = [\n",
    "              # 'new-york-split_scenario-part-1__2022-06-03_17-21-39_iqs/ITERS/it.0/0.plans.csv.gz', \n",
    "              # 'new-york-split_scenario-part-2__2022-06-15_14-26-18_cuu/ITERS/it.0/0.plans.csv.gz', \n",
    "              # 'new-york-split_scenario-part-3__2022-06-15_14-26-18_dmi/ITERS/it.0/0.plans.csv.gz',\n",
    "              'new-york-300k-calibration-7__2022-06-25_17-40-03_aui/ITERS/it.10/10.plans.csv.gz',\n",
    "              'new-york-300k-calibration-11__2022-06-28_21-55-14_hbf/ITERS/it.10/10.plans.csv.gz', \n",
    "              # 'new-york-300k-calibration-12__2022-06-28_21-54-34_tav/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-300k-calibration-13__2022-06-29_17-21-34_psu/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-300k-calibration-15__2022-06-30_15-57-54_zqu/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-300k-calibration-16__2022-07-04_14-46-10_wvt/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-300k-calibration-17__2022-07-05_20-44-02_ccs/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-450k-calibration-18__2022-07-08_15-39-57_pxy/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-450k-calibration-19__2022-07-12_17-14-44_esm/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-450k-calibration-20__2022-07-12_22-31-28_czx/ITERS/it.10/10.plans.csv.gz',\n",
    "              # 'new-york-baseline-0-of-10__2022-07-17_01-19-13_fgz/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-3-of-10__2022-07-17_01-19-21_soy/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-4-of-10__2022-07-17_01-19-20_qig/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-5-of-10__2022-07-17_01-19-12_yyt/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-6-of-10__2022-07-17_01-19-12_dgi/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-7-of-10__2022-07-17_01-19-14_qip/ITERS/it.5/5.plans.csv.gz',\n",
    "              # 'new-york-baseline-8-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.plans.csv.gz'\n",
    "#               'new-york-baseline-2-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.plans.csv.gz',\n",
    "#               'new-york-baseline-9-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.plans.csv.gz',\n",
    "#               'new-york-baseline-1-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.plans.csv.gz'\n",
    "                ]\n",
    "\n",
    "names = [\n",
    "    # 'Baseline Part1',\n",
    "         # 'Baseline Part2',\n",
    "         # 'Baseline Part3',\n",
    "         'Run7',\n",
    "         'Run11',\n",
    "         # 'Run12',\n",
    "         # 'Run13',\n",
    "         # 'Run15',\n",
    "         # 'Run16',\n",
    "         # 'Run17',\n",
    "         # 'Run18',\n",
    "         # 'Run19',\n",
    "         # 'Run20',\n",
    "         # 'Run21-0/10-fullpop', \n",
    "         # 'Run21-3/10-fullpop', \n",
    "         # 'Run21-4/10-fullpop', \n",
    "         # 'Run21-5/10-fullpop', \n",
    "         # 'Run21-6/10-fullpop', \n",
    "         # 'Run21-7/10-fullpop', \n",
    "         # 'Run21-8/10-fullpop',\n",
    "        #  'Run21-2/10-fullpop', \n",
    "        #  'Run21-9/10-fullpop', \n",
    "        #  'Run21-1/10-fullpop', \n",
    "        ]\n",
    "\n",
    "#######################################################################################################################\n",
    "# fp = \"s3://beam-outputs/\"\n",
    "# output_nm = 'SummaryTable_Pilates_invrepo_disabilities.csv'\n",
    "# len_id_transit = 2\n",
    "# fp_res = 'outputs/'\n",
    "# is_NYC = False\n",
    "# is_WC = True\n",
    "# data_names = [\n",
    "#                 'pilates-outputs/sfbay-base-20220409/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.125-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.25-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.5-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_1.75-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_0.5-20220528/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_1.5-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_2.0-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_0.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_0.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_1.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_3.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_0.2-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_0.5-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_1.5-20220614/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_5.0-20220616/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.2-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.5-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.8-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_1.6-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.0-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.75-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_1.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-pilates_june_test-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_price_0.5-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-1T-20220721/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-1T-SF-VT-20220722/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.0_dist_0.0-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.2_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.3-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.6-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.6_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-5veh__2022-07-20_21-48-51_yti/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-10veh__2022-07-20_21-48-52_ucj/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-20veh__2022-07-20_21-48-54_xwf/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-50veh__2022-07-20_21-49-07_oyq/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-100veh__2022-07-20_21-49-00_lgi/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-5veh__2022-07-15_04-13-50_ntn/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-10veh__2022-07-15_04-13-44_okn/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-20veh__2022-07-15_04-13-46_szz/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-50veh__2022-07-15_04-13-48_qbr/ITERS/it.2/2.events.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-100veh__2022-07-15_04-13-44_apr/ITERS/it.2/2.events.csv.gz',\n",
    "#              ]\n",
    "\n",
    "# plan_names = [\n",
    "#                 'pilates-outputs/sfbay-base-20220409/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.125-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.25-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_0.5-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-RH_fleetsz_1.75-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_0.5-20220528/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_1.5-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-transit_frequencies_2.0-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_0.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_0.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_1.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_repo_3.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_0.2-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_0.5-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_1.5-20220614/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_radius_5.0-20220616/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.2-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.5-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_0.8-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_wt_1.6-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.0-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_0.75-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_detour_1.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-pilates_june_test-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_price_0.5-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-1T-20220721/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-1T-SF-VT-20220722/beam/year-2018-iteration-2/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.0_dist_0.0-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.2_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.3-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.6-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_0.6_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "                # 'pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-5veh__2022-07-20_21-48-51_yti/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-10veh__2022-07-20_21-48-52_ucj/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-20veh__2022-07-20_21-48-54_xwf/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-50veh__2022-07-20_21-49-07_oyq/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-100veh__2022-07-20_21-49-00_lgi/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-5veh__2022-07-15_04-13-50_ntn/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-10veh__2022-07-15_04-13-44_okn/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-20veh__2022-07-15_04-13-46_szz/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-50veh__2022-07-15_04-13-48_qbr/ITERS/it.2/2.plans.csv.gz',\n",
    "#                 'output/sfbay/sfbay-pilates-50pop-100veh__2022-07-15_04-13-44_apr/ITERS/it.2/2.plans.csv.gz',\n",
    "#              ]\n",
    "# names = [         \n",
    "#                 'Baseline/year-2018-iteration-5',\n",
    "                # 'sfbay-RH_fleetsz_0.125',\n",
    "                # 'sfbay-RH_fleetsz_0.25',\n",
    "                # 'sfbay-RH_fleetsz_0.5',\n",
    "                # 'sfbay-RH_fleetsz_1.75',\n",
    "                # 'sfbay-transit_frequencies_0.5',\n",
    "                # 'sfbay-transit_frequencies_1.5',\n",
    "                # 'sfbay-transit_frequencies_2.0',\n",
    "                # 'sfbay-rh_repo_0.0',\n",
    "                # 'sfbay-rh_repo_0.5',\n",
    "                # 'sfbay-rh_repo_1.5',\n",
    "                # 'sfbay-rh_repo_3.0',\n",
    "                # 'sfbay-rh_radius_0.2',\n",
    "                # 'sfbay-rh_radius_0.5',\n",
    "                # 'sfbay-rh_radius_1.5',\n",
    "                # 'sfbay-rh_radius_5.0',\n",
    "                # 'sfbay-rh_wt_0.2',\n",
    "                # 'sfbay-rh_wt_0.5',\n",
    "                # 'sfbay-rh_wt_0.8',\n",
    "                # 'sfbay-rh_wt_1.6',\n",
    "                # 'sfbay-rh_detour_0.0',\n",
    "                # 'sfbay-rh_detour_0.5',\n",
    "                # 'sfbay-rh_detour_0.75',\n",
    "                # 'sfbay-rh_detour_1.5',\n",
    "                # 'sfbay-cp_pilatesJune2022',\n",
    "                # 'sfbay-rh_price_0.5',\n",
    "                # '1TEMPO',\n",
    "                # '1T-SF-VT',\n",
    "                # 'sfbay-rh_invrepo_dem_0.0_dist_0.0',\n",
    "                # 'sfbay-rh_invrepo_dem_0.2_dist_0.9',\n",
    "                # 'sfbay-rh_invrepo_dem_0.4_dist_0.3',\n",
    "                # 'sfbay-rh_invrepo_dem_0.4_dist_0.6',\n",
    "                # 'sfbay-rh_invrepo_dem_0.4_dist_1.0',\n",
    "                # 'sfbay-rh_invrepo_dem_0.6_dist_0.9',\n",
    "                # 'sfbay-rh_invrepo_dem_1.0_dist_0.9',\n",
    "                # 'sfbay-rh_invrepo_dem_1.0_dist_1.0',\n",
    "                # 'Disabilities 5% RH WC 50% RH fleet',\n",
    "                # 'Disabilities 10% RH WC 50% RH fleet',\n",
    "                # 'Disabilities 20% RH WC 50% RH fleet',\n",
    "                # 'Disabilities 50% RH WC 50% RH fleet',\n",
    "                # 'Disabilities 100% RH WC 50% RH fleet',\n",
    "                # 'Disabilities 5% RH WC 100% RH fleet',\n",
    "                # 'Disabilities 10% RH WC 100% RH fleet',\n",
    "                # 'Disabilities 20% RH WC 100% RH fleet',\n",
    "                # 'Disabilities 50% RH WC 100% RH fleet',\n",
    "                # 'Disabilities 100% RH WC 100% RH fleet']\n",
    "#######################################################################################################################\n",
    "\n",
    "# Nomenclature\n",
    "PTsColumns = [\n",
    "    'vehicle','time','type','mode','length','vehicleType','arrivalTime','departureTime',\n",
    "        'capacity','secondaryFuel','primaryFuelType','secondaryFuelType','numPassengers','primaryFuel',\n",
    "        ]\n",
    "MCsColumns = ['person','time','type','mode','length']\n",
    "\n",
    "summaryTable = pd.DataFrame()\n",
    "\n",
    "PTsModes = np.array(['walk','bike','car','car_RideHail','car_RideHail_empty','car_RideHail_WC','car_RideHail_WC_empty',\n",
    "                               'car_CAV','car_hov2','car_hov3','bus','tram','rail','subway',\n",
    "                               'cable_car','ferry','bus_empty','tram_empty','rail_empty',\n",
    "                               'subway_empty','cable_car_empty','ferry_empty'])\n",
    "\n",
    "PTsModesNames = ['Walk','Bike','Car','Ride Hail','Empty Ride Hail','Ride Hail WC','Empty Ride Hail WC',\n",
    "                           'CAV','Car HOV2','Car HOV3','Bus','Tram','Rail','Subway',\n",
    "                           'Cable Car','Ferry','Empty Bus','Empty Tram','Empty Rail',\n",
    "                           'Empty Subway','Empty Cable Car','Empty Ferry',]\n",
    "\n",
    "\n",
    "transit_modes = ['bus', 'subway', 'tram', 'rail','cable_car', 'ferry']\n",
    "\n",
    "transit_MCmodes = ['bus', 'subway', 'tram', 'rail', 'walk_transit', 'ride_hail_transit',\n",
    "                            'drive_transit', 'cable_car','bike_transit']\n",
    "\n",
    "MCsModes = np.array([ 'bus', 'subway', 'tram', 'rail', 'car', 'hov3_teleportation', \n",
    "                            'bike', 'hov2_teleportation', 'walk', 'car_hov2', 'car_hov3', \n",
    "                            'walk_transit', 'ride_hail', 'ride_hail_transit', 'ride_hail_pooled', \n",
    "                            'drive_transit', 'cable_car','bike_transit'])\n",
    "\n",
    "MCsModesNames = [ 'Bus', 'Subway', 'Tram', 'Rail', 'Car', 'HOV3 Passenger', 'Bike', \n",
    "                   'HOV2 Passenger', 'Walk', 'HOV2 Driver', 'HOV3 Driver', \n",
    "                   'Walk-Transit', 'Ride Hail', 'Ride Hail-Transit', 'Ride Hail Pooled', \n",
    "                   'Drive-Transit', 'Cable Car', 'Bike-Transit']\n",
    "\n",
    "primaryFuelTypes =['Biodiesel','Diesel','Gasoline','Electricity','Food']\n",
    "\n",
    "CtV = {0:'SUM',\n",
    "      1:'AV',\n",
    "      2:'VAR',\n",
    "      3:'STD',\n",
    "      4:'MIN',\n",
    "      5:'Q1ST',\n",
    "      6:'Q2ND',\n",
    "      7:'Q3RD',\n",
    "      8:'MAX',\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dfae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time 1658991264.2036214 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('Start time',start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102925ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA(data, code):\n",
    "    \n",
    "    #data is a list of values\n",
    "    #code - operation\n",
    "    #0 - Sum\n",
    "    #1 - Mean\n",
    "    #2 - Var\n",
    "    #3 - Std error\n",
    "    #4 - Min\n",
    "    #5 - Q1\n",
    "    #6 - Q2\n",
    "    #7 - Q3\n",
    "    #8 - Max\n",
    "    if len(data)>0:\n",
    "        if code == 0:\n",
    "            value = np.sum(data)\n",
    "        elif code == 1:\n",
    "            value = np.mean(data)\n",
    "        elif code == 2:\n",
    "            value = np.var(data)\n",
    "        elif code == 3:\n",
    "            value = np.std(data)\n",
    "        elif code == 4:\n",
    "            value = np.min(data)\n",
    "        elif code == 5:\n",
    "            value = np.percentile(data, 25)\n",
    "        elif code == 6:\n",
    "            value = np.percentile(data, 50)\n",
    "        elif code == 7:\n",
    "            value = np.percentile(data, 75)\n",
    "        elif code == 8:\n",
    "            value = np.max(data)\n",
    "    else:\n",
    "        value = np.nan\n",
    "\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a45d95b-69f9-45cf-92f9-ea887f35c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PtoPTss = personToPathTraversal(PT s,PEVs,PLVs,personToTripDepartures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1c7479-d2cf-4513-8b93-c586581ed12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def personToPathTraversal(PTs, PEVs, PLVs, personToTripDeparture):\n",
    "    print('personToPathTraversal...')\n",
    "    no_legs_after_time_check = []\n",
    "    no_legs = []\n",
    "    start = time.time()\n",
    "    for pt_mode in PTs['mode'].value_counts().keys():\n",
    "        print('expected PtoPTs from occupancy ',pt_mode,  int(np.sum(PTs[PTs['mode']==pt_mode]['occupancy'])))\n",
    "    print('expected PtoPTs from occupancy TOT = ', np.sum(PTs['occupancy']))\n",
    "    print('len of PEV = ', len(PEVs))\n",
    "    print('len of PLV = ', len(PLVs))\n",
    "\n",
    "    vehicleToPT = PTs.groupby('vehicle').apply(lambda x: list(x.index)).apply(\n",
    "        lambda x: {y: [] for y in x}).to_dict()\n",
    "    PEVlookup = PEVs[['person', 'vehicle', 'time']].value_counts().to_dict()\n",
    "    PLVlookup = PLVs.groupby(['person', 'vehicle']).apply(lambda x: list(x.time)).to_dict()\n",
    "\n",
    "    for key, counts in PEVlookup.items():\n",
    "        person = key[0]\n",
    "        vehicle = key[1]\n",
    "        departureTime = key[2]\n",
    "        n_new_leg = 0\n",
    "        if vehicle in vehicleToPT:\n",
    "            legs = vehicleToPT[vehicle]\n",
    "            if (person, vehicle) in PLVlookup:\n",
    "                if person in personToTripDeparture:\n",
    "                    planTrips = personToTripDeparture[person]\n",
    "                    tripsLeavingBeforeDeparture = [-1] + [t['planID'] for t in planTrips if\n",
    "                                                          t['departureTime'] <= (departureTime+1)]\n",
    "                                                                                     #+ 1800)]\n",
    "                else:\n",
    "                    tripsLeavingBeforeDeparture = [-1]\n",
    "                    print('no person',person, 'on personToTripDeparture...','vehicle',vehicle,'departureTime',departureTime,'personToTripDeparture',personToTripDeparture[person])\n",
    "\n",
    "                lastTripBeforeDeparture = tripsLeavingBeforeDeparture[-1]\n",
    "                if lastTripBeforeDeparture == -1:\n",
    "                    print('hmm...if person on personToTripDeparture, no plans starting before departure')\n",
    "                \n",
    "                endTimes = PLVlookup[(person, vehicle)]\n",
    "                plvsAfterDeparture = [t for t in endTimes if t > departureTime]\n",
    "                if len(plvsAfterDeparture) > 0:\n",
    "                    firstPLVafterDeparture = plvsAfterDeparture[0]\n",
    "                    n_new_leg = 0\n",
    "                    for leg in legs.keys():\n",
    "                        ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                        if (ptDepartureTime >= departureTime) & (ptDepartureTime < firstPLVafterDeparture):\n",
    "                            n_new_leg +=1\n",
    "                            legs[leg].append((person, lastTripBeforeDeparture))\n",
    "                            \n",
    "                else:\n",
    "                    for leg in legs.keys():\n",
    "                        n_new_leg = 0\n",
    "                        ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                        if ptDepartureTime >= departureTime:\n",
    "                            n_new_leg +=1\n",
    "                            legs[leg].append((person, lastTripBeforeDeparture))\n",
    "            else:\n",
    "\n",
    "                if person in personToTripDeparture:\n",
    "                    planTrips = personToTripDeparture[person]\n",
    "                    tripsLeavingBeforeDeparture = [-1] + [t['planID'] for t in planTrips if\n",
    "                                                          t['departureTime'] <= (departureTime+1)]\n",
    "                                                                                     #+ 1800)]\n",
    "                else:\n",
    "                    tripsLeavingBeforeDeparture = [-1]\n",
    "                    print('no person',person, 'on personToTripDeparture...','vehicle',vehicle,'departureTime',departureTime,'personToTripDeparture',personToTripDeparture[person])\n",
    "\n",
    "                lastTripBeforeDeparture = tripsLeavingBeforeDeparture[-1]\n",
    "                if lastTripBeforeDeparture == -1:\n",
    "                    print('hmm...if person on personToTripDeparture, no plans starting before departure')\n",
    "                n_new_leg = 0\n",
    "                for leg in legs.keys():\n",
    "                    ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                    if ptDepartureTime >= departureTime:\n",
    "                        n_new_leg +=1\n",
    "                        legs[leg].append((person, lastTripBeforeDeparture))\n",
    "            if n_new_leg == 0:\n",
    "                no_legs_after_time_check.append(vehicle)\n",
    "#                 print(\"Warning: no vehicle legs (after time check) for person, vehicle, depTime\", person, vehicle, departureTime)\n",
    "        else:\n",
    "                no_legs.append(vehicle)\n",
    "#             print(\"Warning: no vehicle legs for person, vehicle, depTime\", person, vehicle, departureTime)\n",
    "\n",
    "    PtoPTssList = [(veh, pathTraversalID, passenger, planIndex) for veh, vehicleLegs in\n",
    "                                vehicleToPT.items() for pathTraversalID, passengers in vehicleLegs.items() for\n",
    "                                (passenger, planIndex) in passengers if len(passengers) > 0]\n",
    "    PtoPTss = pd.MultiIndex.from_tuples(PtoPTssList,\n",
    "                                                     name=['vehicleID', 'pathTraversalID', 'personID',\n",
    "                                                           'planIndex']).to_frame()\n",
    "    modes_PtoPTss = []\n",
    "    lengths_PtoPTss = []\n",
    "    durations_PtoPTss = []\n",
    "    prim_fuel_type_PtoPTss = []\n",
    "    \n",
    "    for pt_id in PtoPTss['pathTraversalID']:\n",
    "        modes_PtoPTss.append(PTs.at[pt_id,'mode'])\n",
    "        lengths_PtoPTss.append(PTs.at[pt_id,'length'])\n",
    "        durations_PtoPTss.append(PTs.at[pt_id,'duration'])\n",
    "        prim_fuel_type_PtoPTss.append(PTs.at[pt_id,'primaryFuelType'])\n",
    "\n",
    "    PtoPTss['mode'] = modes_PtoPTss\n",
    "    PtoPTss['length'] = lengths_PtoPTss\n",
    "    PtoPTss['duration'] = durations_PtoPTss\n",
    "    PtoPTss['primaryFuelType'] = prim_fuel_type_PtoPTss\n",
    "\n",
    "    vehicles_2 = []\n",
    "    for pt_id in PtoPTss['pathTraversalID']:\n",
    "        vehicles_2.append(PTs.at[pt_id,'vehicle'][:len_id_transit])\n",
    "    vehicles_2 = np.array(vehicles_2)\n",
    "    PtoPTss['vehicle2'] = vehicles_2\n",
    "    \n",
    "    modes,counts = np.unique(modes_PtoPTss, return_counts = True)\n",
    "    for mode, count in zip(modes, counts):\n",
    "        print('len PtoPTs after matching agents and vehicles',mode,count)\n",
    "        \n",
    "    print('no legs found:', len(no_legs))\n",
    "    print('no legs found after time check:', len(no_legs_after_time_check))\n",
    "    print('no vehicle body found, probably because with zero duration (discarded bu PT):', \n",
    "          len(list(filter(lambda k: 'body' in k, no_legs))))\n",
    "    print('no vehicle body found after time check, probably because with zero duration (discarded bu PT):', \n",
    "          len(list(filter(lambda k: 'body' in k, no_legs_after_time_check))))\n",
    "    print('Tot created PtoPTs = ', len(PtoPTss))\n",
    "    PtoPTss.index = range(len(PtoPTss))\n",
    "    print('Total time:', time.time()-start)\n",
    "    return PtoPTss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e70e50-9441-4f8a-bb95-b2b326794086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def processPlans(directory):\n",
    "    #fullPath = directory + 'plans.csv.gz'\n",
    "    print('processPlans...')\n",
    "    start = time.time()\n",
    "    trips = []\n",
    "    activities = []\n",
    "    personToTripDeparture = {}\n",
    "    print(directory)\n",
    "    df = pd.read_csv(directory, nrows = None)\n",
    "    # print(df.keys())\n",
    "    df = df[df['planSelected']==True]\n",
    "    # print(df[df['personId']==194])\n",
    "    df = addTimesToPlans(df)\n",
    "    legs = df.loc[(df['planElementType'].str.lower().str.contains('leg'))].dropna(how='all', axis=1)\n",
    "    legs = (legs[legs['legDepartureTime']>=0])\n",
    "    # print(legs.keys())\n",
    "    # print(legs)\n",
    "    try:\n",
    "        legsSub = legs[['personId', 'legDepartureTime',  'planElementIndex', 'legMode', 'originX', 'originY', 'destinationX', 'destinationY']]\n",
    "        is_leg_mode = True\n",
    "    except:\n",
    "        legsSub = legs[['personId', 'legDepartureTime',  'planElementIndex', 'originX', 'originY', 'destinationX', 'destinationY']]\n",
    "        is_leg_mode = False\n",
    "\n",
    "    for rowID, val in legsSub.iterrows():\n",
    "        personToTripDeparture.setdefault(val.personId, []).append(\n",
    "            {\"planID\": val.planElementIndex, \"departureTime\": val.legDepartureTime})\n",
    "    #TRIPS\n",
    "    trips.append(legsSub)\n",
    "    #ACTS\n",
    "    acts = df.loc[(df['planElementType'].str.lower().str.contains('activity'))].dropna(how='all', axis=1)\n",
    "    actsSub = acts[['personId', 'activityType', 'activityLocationX', 'activityLocationY', 'activityEndTime']]\n",
    "    activities.append(actsSub)\n",
    "    print('Total time:', time.time()-start)\n",
    "    return pd.concat(trips), pd.concat(activities), personToTripDeparture, is_leg_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724571a8-9308-495f-bf2d-7ddffdfd600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTimesToPlans(plans):\n",
    "    print('addTimesToPlans...')\n",
    "    start = time.time()\n",
    "    legInds = np.where(plans['planElementType'].str.lower() == \"leg\")[0]\n",
    "    plans.loc[:, 'legDepartureTime'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('legDepartureTime')] = plans['activityEndTime'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'originX'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('originX')] = plans['activityLocationX'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'originY'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('originY')] = plans['activityLocationY'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'destinationX'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('destinationX')] = plans['activityLocationX'].iloc[legInds + 1].copy()\n",
    "    plans.loc[:, 'destinationY'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('destinationY')] = plans['activityLocationY'].iloc[legInds + 1].copy()\n",
    "    print('Total time:', time.time()-start)\n",
    "    return plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869d0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readEvents(directory):\n",
    "    #fullPath = directory + 'ITERS/it.0/0.events.csv.gz'\n",
    "    PTs = []\n",
    "    PEVs = []\n",
    "    PLVs = []\n",
    "    MCs = []\n",
    "    RPs = []\n",
    "    print('Reading ', directory)\n",
    "    for chunk in pd.read_csv(directory, chunksize=2500000, nrows = nrows):\n",
    "        if sum((chunk['type'] == 'PathTraversal')) > 0:\n",
    "            chunk['vehicle'] = chunk['vehicle'].astype(str)\n",
    "            \n",
    "            #PT\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PathTraversal')]),': len chunk PT')\n",
    "            PT = chunk.loc[(chunk['type'] == 'PathTraversal') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "            PT['departureTime'] = PT['departureTime'].astype(int)\n",
    "            PT['arrivalTime'] = PT['arrivalTime'].astype(int)\n",
    "            PTs.append(PT[PTsColumns])\n",
    "            print(len(PT),': after filtering zero-length PT')\n",
    "            #PEV\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PersonEntersVehicle')]),': len chunk PEV')\n",
    "#             PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") & \n",
    "#                             ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) & \n",
    "#                             ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "            PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") &\n",
    "                            ~(chunk['person'].apply(str).str.contains('Agent').fillna(False))\n",
    "                            , :].dropna(how='all', axis=1)\n",
    "            print(len(PEV),': after filtering drivers')\n",
    "                                                                                                                    \n",
    "            if ~PEV.empty:\n",
    "                PEV['person'] = PEV['person'].astype(int)\n",
    "                PEV['time'] = PEV['time'].astype(int)\n",
    "                PEVs.append(PEV)\n",
    "\n",
    "            #PLV\n",
    "#             PLV = chunk.loc[(chunk.type == \"PersonLeavesVehicle\") & \n",
    "#                             ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) & \n",
    "#                             ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PersonLeavesVehicle')]),': len chunk PLV')\n",
    "            PLV = chunk.loc[(chunk.type == \"PersonLeavesVehicle\") &\n",
    "                            ~(chunk['person'].apply(str).str.contains('Agent').fillna(False))\n",
    "                            , :].dropna(how='all', axis=1) \n",
    "            print(len(PLV),': after filtering drivers')\n",
    "            if ~PLV.empty:\n",
    "                PLV['person'] = PLV['person'].astype(int)\n",
    "                PLV['time'] = PLV['time'].astype(int)\n",
    "                PLVs.append(PLV)\n",
    "        if sum((chunk['type'] == 'ModeChoice')) > 0:\n",
    "            #MC\n",
    "            MC = chunk.loc[(chunk['type'] == 'ModeChoice') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "            MCs.append(MC[MCsColumns])\n",
    "            \n",
    "        if sum((chunk['type'] == 'Replanning')) > 0:\n",
    "            #RP\n",
    "            RP = chunk.loc[(chunk['type'] == 'Replanning')].dropna(how='all', axis=1)\n",
    "            RPs.append(RP)\n",
    "        \n",
    "    print(len(pd.concat(PEVs)),':len PEVs')\n",
    "    print(len(pd.concat(PLVs)),':len PLVs')\n",
    "    \n",
    "    PEVs = pd.concat(PEVs)\n",
    "    PLVs = pd.concat(PLVs)\n",
    "    PTs = pd.concat(PTs)\n",
    "    MCs = pd.concat(MCs)\n",
    "    RPs = pd.concat(RPs)\n",
    "\n",
    "    \n",
    "    print(len(PTs),':len PTs')\n",
    "    print(len(MCs),':len MCs')\n",
    "    print(len(RPs),':len RPs')\n",
    "\n",
    "    \n",
    "    return MCs, PTs, PEVs, PLVs, RPs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be67b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixData(Mcs, PTs, PEVs, PLVs,len_id_transit):\n",
    "\n",
    "    PTs['duration'] = PTs['arrivalTime'] - PTs['departureTime']\n",
    "    PTs['gallonsGasoline'] = 0\n",
    "    PTs.loc[PTs['primaryFuelType'] == 'Gasoline',\n",
    "            'gallonsGasoline'] += PTs.loc[PTs['primaryFuelType'] == 'Gasoline', 'primaryFuel'] * 8.3141841e-9\n",
    "    PTs.loc[PTs['secondaryFuelType'] == 'Gasoline',\n",
    "            'gallonsGasoline'] += PTs.loc[PTs['secondaryFuelType'] == 'Gasoline', 'secondaryFuel'] * 8.3141841e-9\n",
    "    PTs['occupancy'] = PTs['numPassengers']\n",
    "    \n",
    "    PTs['isCAV'] = PTs['vehicleType'].str.contains('L5')\n",
    "    PTs['isRH'] = PTs['vehicle'].str.contains('rideHail')\n",
    "    PTs['isRH_WC'] = PTs['vehicleType'].str.contains('RH_Car-wheelchair')\n",
    "    PTs['is_empty'] = PTs['numPassengers'] == 0\n",
    "    PTs['is_RHempty'] = PTs['isRH']*PTs['is_empty']\n",
    "    PTs.loc[PTs['isRH'], 'mode'] += '_RideHail'\n",
    "    PTs.loc[PTs['isRH_WC'], 'mode'] += '_WC'\n",
    "    PTs.loc[PTs['isCAV'], 'mode'] += '_CAV'\n",
    "    PTs.loc[PTs['is_RHempty'], 'mode'] += '_empty'\n",
    "\n",
    "    PTs.loc[PTs['mode'] == 'car', 'occupancy'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov2', 'occupancy'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov3', 'occupancy'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'walk', 'occupancy'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'bike', 'occupancy'] = 1\n",
    "    \n",
    "    PTs.loc[PTs['mode'] == 'car', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov2', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov3', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'walk', 'capacity'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'bike', 'capacity'] = 1\n",
    "    \n",
    "    for tm in transit_modes:\n",
    "        PTs['is'+tm] = PTs['mode'].str.contains(tm)\n",
    "    for tm in transit_modes:\n",
    "        PTs['is_'+tm+'_empty'] = PTs['is'+tm]*PTs['is_empty']\n",
    "    PTs['is_transit'] = 0\n",
    "    for tm in transit_modes:\n",
    "        PTs['is_transit']+=PTs['is'+tm]\n",
    "    for tm in transit_modes:\n",
    "        PTs.loc[PTs['is_'+tm+'_empty'], 'mode'] += '_empty'\n",
    "        PTs.drop(columns=['is'+tm])\n",
    "        PTs.drop(columns=['is_'+tm+'_empty'])\n",
    "        \n",
    "    PTs.drop(columns=['isCAV','is_empty','is_RHempty',])\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PTs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    vehicles_2 = np.array(vehicles_2)\n",
    "    PTs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PEVs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    PEVs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PLVs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    PLVs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    return Mcs, PTs, PEVs, PLVs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e3958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SummaryTable(ST, data_name, name, plan_name, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss, codes, transitCompanies):\n",
    "    \n",
    "#----------Indexes\n",
    "    PTsModeIndexes = {}\n",
    "    PTsTransitIndexes = {}\n",
    "    PTsFuelIndexes = {}\n",
    "    MCsModeIndexes = {}\n",
    "    MCsReplanIndexes = {}\n",
    "    MCsPlanIndexes = {}\n",
    "    PtoPTssModeIndexes = {}\n",
    "    PtoPTssTransitIndexes = {}\n",
    "    PtoPTssFuelIndexes = {}\n",
    "    #Replanning\n",
    "    reasons = []\n",
    "    for reason in RPs['reason']:\n",
    "        reasons.append(reason.split()[1].lower())\n",
    "    RPs['mode'] = reasons\n",
    "    totalTrips_replan = len(RPs['mode'])\n",
    "    \n",
    "    for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "        MCsReplanIndexes[MCsMode] = RPs[(RPs['mode'] == MCsMode)].index\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        PTsModeIndexes[PTsMode] = PTs[(PTs['mode'] == PTsMode)].index\n",
    "        PtoPTssModeIndexes[PTsMode] = PtoPTss[(PtoPTss['mode'] == PTsMode)].index\n",
    "    for company in transitCompanies:\n",
    "        PTsTransitIndexes[company] = PTs[(PTs['vehicle2'] == company)].index\n",
    "        PtoPTssTransitIndexes[company] = PtoPTss[(PtoPTss['vehicle2'] == company)].index\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        PTsFuelIndexes[primaryFuelType] = PTs[(PTs['primaryFuelType'] == primaryFuelType)].index\n",
    "        PtoPTssFuelIndexes[primaryFuelType] = PtoPTss[(PtoPTss['primaryFuelType'] == primaryFuelType)].index\n",
    "    for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "        MCsModeIndexes[MCsMode] = MCs[(MCs['mode'] == MCsMode)].index\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "            MCsPlanIndexes[MCsMode] = trips[(trips['legMode'] == MCsMode)].index\n",
    "\n",
    "    ST.at['Simulated Agents ', name] = len(pd.unique(trips['personId'])) \n",
    "    ST.at['Trips per Agent AV ', name] = len(trips)/len(pd.unique(trips['personId']))\n",
    "    \n",
    "#----------Number Trips\n",
    "#check plans for estimated mode share, trip per person\n",
    "    totalTrips_vehicle = len(PTs['mode'])\n",
    "    totalTrips_est = len(trips)\n",
    "    totalTrips_mode = len(MCs['mode'])\n",
    "    totalTrips_replan = len(RPs)\n",
    "    totalTrips_exec = totalTrips_mode-len(RPs)\n",
    "    \n",
    "    print('Number Trips...',name)\n",
    "    ST.at['Trip Vehicle Total ', name] = totalTrips_vehicle\n",
    "    ST.at['Trip Est Total ', name] = totalTrips_est\n",
    "    ST.at['Trip Mode Total ', name] = totalTrips_mode\n",
    "    ST.at['Trip Replanning Total ', name] = totalTrips_replan\n",
    "    ST.at['Trip Exectuted Total ', name] = totalTrips_exec\n",
    "\n",
    "    \n",
    "    \n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        ST.at['Trip Vehicle '+PTsModesName, name] = len(PTsModeIndexes[PTsMode])\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "            ST.at['Trip Est '+MCsName, name] = len(MCsPlanIndexes[MCsMode])\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Mode '+MCsName, name] = len(MCsModeIndexes[MCsMode])\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Replan '+MCsName, name] = len(MCsReplanIndexes[MCsMode])\n",
    "    transit_exec = 0\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Exec '+MCsName, name] = len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode])\n",
    "        if MCsMode in transit_MCmodes:\n",
    "            transit_exec += len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode])\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        ST.at['Trip Vehicle '+primaryFuelType, name] = len(PTsFuelIndexes[primaryFuelType])\n",
    "    for company in transitCompanies:\n",
    "        ST.at['Trip Vehicle '+company, name] = len(PTsTransitIndexes[company])\n",
    "        \n",
    "#----------Share Trips\n",
    "    print('Share Trips...',name)\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        ST.at['Trip Vehicle Share '+PTsModesName, name] = len(PTsModeIndexes[PTsMode])/totalTrips_vehicle\n",
    "    for company in transitCompanies:\n",
    "        ST.at['Trip Vehicle Share '+company, name] = len(PTsTransitIndexes[company])/totalTrips_vehicle\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "            ST.at['Trip Est Share '+MCsName, name] = len(MCsPlanIndexes[MCsMode])/totalTrips_est\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Mode Share '+MCsName, name] = len(MCsModeIndexes[MCsMode])/totalTrips_mode\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Replan Share '+MCsName, name] = len(MCsReplanIndexes[MCsMode])/totalTrips_replan\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Exec Share '+MCsName, name] = (len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode]))/totalTrips_exec\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        ST.at['Trip Vehicle Share '+primaryFuelType, name] = len(PTsFuelIndexes[primaryFuelType])/totalTrips_vehicle\n",
    "\n",
    "\n",
    "\n",
    "#----------Trip Lengths\n",
    "    #----------------------Vehicles\n",
    "    print('Lengths Vehicles...',name)\n",
    "    lengths = PTs['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Vehicle'+CtV[code]+' [km]', name] = DA(lengths, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+PTsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+company+' [km]', name] = DA(lengths_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            lengths_fueltype = lengths[PTsFuelIndexes[primaryFuelType]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+primaryFuelType+' [km]', name] = DA(lengths_fueltype, code)  \n",
    "    \n",
    "    #----------------------Persons\n",
    "    print('Lengths Persons...',name)\n",
    "    lengths = PtoPTss['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Person'+CtV[code]+' [km]', name] = DA(lengths, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            lengths_mode = lengths[PtoPTssModeIndexes[PTsMode]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+PTsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            lengths_company = lengths[PtoPTssTransitIndexes[company]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+company+' [km]', name] = DA(lengths_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            lengths_fueltype = lengths[PtoPTssFuelIndexes[primaryFuelType]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+primaryFuelType+' [km]', name] = DA(lengths_fueltype, code)  \n",
    "    \n",
    "    \n",
    "    #----------------------Modes\n",
    "    print('Lengths Modes...',name)\n",
    "    lengths = MCs['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Trip '+CtV[code]+'[km]', name] = DA(lengths, code)\n",
    "        for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "            lengths_mode = lengths[MCsModeIndexes[MCsMode]]\n",
    "            ST.at['Length Mode '+CtV[code]+' '+MCsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "   \n",
    "    lengths = PTs['length']/1000.\n",
    "    \n",
    " #----------Trip Durations\n",
    "    print('Durations Vehicle...',name)\n",
    "    durations = PTs['duration']/3600.\n",
    "    for code in codes:\n",
    "        ST.at['Duration Vehicle'+CtV[code]+' [h]', name] = DA(durations, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            durations_mode = durations[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+PTsModesName+' [h]', name] = DA(durations_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            durations_company = durations[PTsTransitIndexes[company]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+company+' [h]', name] = DA(durations_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            durations_fueltype = durations[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+primaryFuelType+' [h]', name] = DA(durations_fueltype, code)   \n",
    "     \n",
    "    #----------Persons\n",
    "    print('Durations Person...',name)\n",
    "    durations = PtoPTss['duration']/3600.\n",
    "    for code in codes:\n",
    "        ST.at['Duration Vehicle'+CtV[code]+' [h]', name] = DA(durations, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            durations_mode = durations[PtoPTssModeIndexes[PTsMode]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+PTsModesName+' [h]', name] = DA(durations_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            durations_company = durations[PtoPTssTransitIndexes[company]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+company+' [h]', name] = DA(durations_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            durations_fueltype = durations[PtoPTssFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+primaryFuelType+' [h]', name] = DA(durations_fueltype, code)   \n",
    "    \n",
    "    \n",
    "#----------Trip Speeds\n",
    "    print('Speeds Vehicle...',name)\n",
    "    speeds = lengths/durations[(durations>0)]\n",
    "    for code in codes:\n",
    "        ST.at['Speed Vehicle'+CtV[code]+' [km/h]', name] = DA(speeds, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            speeds_mode = speeds[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+PTsModesName+' [km/h]', name] = DA(speeds_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            speeds_company = speeds[PTsTransitIndexes[company]]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+company+' [km/h]', name] = DA(speeds_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            speeds_fueltype = speeds[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+primaryFuelType+' [km/h]', name] = DA(speeds_fueltype, code)   \n",
    "    \n",
    "#----------Energy Consumption\n",
    "    print('Energy Usage Vehicle...',name)\n",
    "    energies = PTs['primaryFuel']/1000000000.+PTs['secondaryFuel']/1000000000.\n",
    "    for code in codes:\n",
    "        ST.at['Energy Vehicle'+CtV[code]+' [GJ]', name] = DA(energies, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            energies_mode = energies[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+PTsModesName+' [GJ]', name] = DA(energies_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            energies_company = energies[PTsTransitIndexes[company]]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+company+' [GJ]', name] = DA(energies_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            energies_fueltype = energies[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+primaryFuelType+' [GJ]', name] = DA(energies_fueltype, code)   \n",
    "\n",
    "#----------Trip Gallons\n",
    "    print('Trip Gallons Vehicle...',name)\n",
    "    gallons = PTs['gallonsGasoline']\n",
    "    for code in codes:\n",
    "        ST.at['Gallons Gas Vehicle'+CtV[code]+' [gallon]', name] = DA(gallons, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            gallons_mode = gallons[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+PTsModesName+' [gallon]', name] = DA(gallons_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            gallons_company = gallons[PTsTransitIndexes[company]]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+company+' [gallonh]', name] = DA(gallons_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            gallons_fueltype = gallons[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+primaryFuelType+' [gallon]', name] = DA(gallons_fueltype, code)   \n",
    "    \n",
    "#----------Occupancy\n",
    "    print('Occupancy Vehicle...',name)\n",
    "    passengers = PTs['occupancy']\n",
    "    capacities = PTs['capacity']\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Passengers stops '+company, name] = np.sum(passenger_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Passengers km '+company, name] = np.sum(passenger_company*lengths_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        capacities_company = capacities[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Capacity km '+company, name] = np.sum(capacities_company*lengths_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        capacities_company = capacities[PTsTransitIndexes[company]]\n",
    "        if np.sum(capacities_company*lengths_company)>0:\n",
    "            ST.at['Vehicle Load Factor '+company, name] = np.sum(passenger_company*lengths_company)/np.sum(capacities_company*lengths_company)\n",
    "\n",
    "    ST.at['Vehicle Person km Total ', name] = np.sum(lengths*passengers)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            passengers_mode = passengers[PTsModeIndexes[PTsMode]] \n",
    "            ST.at['Vehicle Person km '+PTsModesName, name] = np.sum(lengths_mode*passengers_mode)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            capacities_mode = capacities[PTsModeIndexes[PTsMode]] \n",
    "            ST.at['Vehicle Capacity km '+PTsModesName, name] = np.sum(lengths_mode*capacities_mode)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            passengers_mode = passengers[PTsModeIndexes[PTsMode]] \n",
    "            capacities_mode = capacities[PTsModeIndexes[PTsMode]] \n",
    "            if np.sum(lengths_mode*capacities_mode)>0:\n",
    "                ST.at['Vehicle Load Factor '+PTsModesName, name] = np.sum(lengths_mode*passengers_mode)/np.sum(lengths_mode*capacities_mode)\n",
    "\n",
    "#----------Ridership\n",
    "    print('Ridership Transit...',name)\n",
    "    total_rs = 0\n",
    "    for company in transitCompanies:\n",
    "        ridership_company = len(PEVs['vehicle'][(PEVs['vehicle2'] == company)])\n",
    "        ST.at['Ridership '+company, name] = ridership_company\n",
    "        total_rs += ridership_company\n",
    "    for company in transitCompanies:\n",
    "        ridership_company = len(PEVs['vehicle'][(PEVs['vehicle2'] == company)])\n",
    "        ST.at['Ridership '+company+' Share', name] = ridership_company/total_rs\n",
    "\n",
    "################################################################################################\n",
    "# ################################################EXTRA FOR NYC################################################\n",
    "    if is_NYC:\n",
    "        PEVs_NJ = PEVs[(PEVs['vehicle2'] == 'NJ_Transit')]\n",
    "        NJ_ridership_bus = 0\n",
    "        NJ_ridership_rail = 0\n",
    "        NJ_ridership_lrail = 0\n",
    "        GTFS_NJ_RAIL_trips = pd.read_csv('GTFS/trips.txt')\n",
    "        for NJ_vehicle in PEVs_NJ['vehicle']:\n",
    "            if NJ_vehicle[:12] == 'NJ_Transit_B':\n",
    "                NJ_ridership_bus += 1\n",
    "            elif NJ_vehicle[:12] == 'NJ_Transit_R':\n",
    "                trip_id = NJ_vehicle.split(':')[1]\n",
    "                route_id = list(GTFS_NJ_RAIL_trips['route_id'][GTFS_NJ_RAIL_trips['trip_id'].astype(str)==trip_id])[0]\n",
    "                if route_id in [4,12,16]:\n",
    "                    NJ_ridership_lrail += 1\n",
    "                else:\n",
    "                    NJ_ridership_rail +=1\n",
    "\n",
    "        ST.at['Ridership NJ Transit Bus', name] = NJ_ridership_bus\n",
    "        ST.at['Ridership NJ Transit Rail', name] = NJ_ridership_rail\n",
    "        ST.at['Ridership NJ Transit Light Rail', name] = NJ_ridership_lrail\n",
    "        ST.at['Ridership NJ Transit Bus Share', name] = NJ_ridership_bus/total_rs\n",
    "        ST.at['Ridership NJ Transit Rail Share', name] = NJ_ridership_rail/total_rs\n",
    "        ST.at['Ridership NJ Transit Light Rail Share', name] = NJ_ridership_lrail/total_rs\n",
    "        \n",
    "    #Check ridership Subway\n",
    "\n",
    "        agencies = []\n",
    "        for vehicle in PtoPTss['vehicleID']:\n",
    "            agencies.append(vehicle[:20])\n",
    "        PtoPTss['agency'] = agencies\n",
    "\n",
    "        grouping = PtoPTss.groupby(['personID','planIndex']).apply(lambda x: [y[0] for y in groupby(x.agency)]).to_dict()\n",
    "        \n",
    "\n",
    "        combinations = []\n",
    "        i = 0\n",
    "        for key in grouping.keys():\n",
    "            i+=1\n",
    "            combinations.append(grouping[key])\n",
    "\n",
    "        ridership_Subway = 0\n",
    "        for comb in combinations:\n",
    "            for c in comb:\n",
    "                if c[:10] =='NYC_Subway':\n",
    "                    ridership_Subway += 1\n",
    "\n",
    "        ST.at['Ridership NYC Subway Without Transfers', name] = ridership_Subway\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "    ST.at['Ridership Total', name] = total_rs\n",
    "    ST.at['Transit Transfer per trip AV', name] = total_rs/transit_exec-1.\n",
    "#----------RH\n",
    "    start_RH = time.time()\n",
    "    print('Ride hail...',name)\n",
    "\n",
    "    PTsRH = PTs[PTs['isRH']]\n",
    "    ST.at['Empty Trips RH', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])\n",
    "    ST.at['Not Empty Trips RH', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])\n",
    "    if len(PTsRH['vehicle']) >0:\n",
    "        ST.at['Empty Trips RH Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])/len(PTsRH['vehicle'])\n",
    "        ST.at['Not Empty Trips RH Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])/len(PTsRH['vehicle'])\n",
    "    \n",
    "    for code in codes:\n",
    "        ST.at[CtV[code]+' Trips per RH Vehicle', name] = DA(PTsRH['vehicle'].value_counts(), code)\n",
    "        \n",
    "    rh_vehicles = pd.unique(PTsRH['vehicle'])\n",
    "    n_empty = []\n",
    "    n_notempty = []\n",
    "    first_trip = []\n",
    "    last_trip = []\n",
    "    for rh_vehicle in rh_vehicles:\n",
    "        PTs_rh_vehicle = PTsRH[PTsRH['vehicle']==rh_vehicle]\n",
    "        n_empty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']==0]))\n",
    "        n_notempty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']>0]))\n",
    "        PTs_rh_vehicle = PTs_rh_vehicle.sort_values(by='time', ascending=True)\n",
    "        first_trip.append(list(PTs_rh_vehicle['numPassengers'])[0])\n",
    "        last_trip.append(list(PTs_rh_vehicle['numPassengers'])[-1])\n",
    "        \n",
    "    share_empty = np.array(n_empty)-np.array(n_notempty)\n",
    "    for code in codes:\n",
    "        ST.at[CtV[code]+' RH Vehicle (Empty - not Empty) Trips', name] = DA(share_empty, code)\n",
    "    \n",
    "    if len(first_trip) >0:\n",
    "        ST.at['RH Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 0)/len(first_trip)\n",
    "        ST.at['RH Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 0)/len(first_trip)\n",
    "        ST.at['RH not Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 1)/len(first_trip)\n",
    "        ST.at['RH not Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 1)/len(first_trip)\n",
    "\n",
    "#----------RH - WC\n",
    "    if is_WC == True:\n",
    "        start_RH = time.time()\n",
    "        print('Ride hail WC...',name)\n",
    "\n",
    "        PTsRH = PTs[PTs['isRH_WC']]\n",
    "        ST.at['Empty Trips RH WC', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])\n",
    "        ST.at['Not Empty Trips RH WC', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])\n",
    "        if len(PTsRH['vehicle']) >0:\n",
    "            ST.at['Empty Trips RH WC Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])/len(PTsRH['vehicle'])\n",
    "            ST.at['Not Empty Trips RH WC Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])/len(PTsRH['vehicle'])\n",
    "\n",
    "        for code in codes:\n",
    "            ST.at[CtV[code]+' Trips per RH WC Vehicle', name] = DA(PTsRH['vehicle'].value_counts(), code)\n",
    "\n",
    "        rh_vehicles = pd.unique(PTsRH['vehicle'])\n",
    "        n_empty = []\n",
    "        n_notempty = []\n",
    "        first_trip = []\n",
    "        last_trip = []\n",
    "        for rh_vehicle in rh_vehicles:\n",
    "            PTs_rh_vehicle = PTsRH[PTsRH['vehicle']==rh_vehicle]\n",
    "            n_empty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']==0]))\n",
    "            n_notempty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']>0]))\n",
    "            PTs_rh_vehicle = PTs_rh_vehicle.sort_values(by='time', ascending=True)\n",
    "            first_trip.append(list(PTs_rh_vehicle['numPassengers'])[0])\n",
    "            last_trip.append(list(PTs_rh_vehicle['numPassengers'])[-1])\n",
    "\n",
    "        share_empty = np.array(n_empty)-np.array(n_notempty)\n",
    "        for code in codes:\n",
    "            ST.at[CtV[code]+' RH WC Vehicle (Empty - not Empty) Trips', name] = DA(share_empty, code)\n",
    "\n",
    "        if len(first_trip) >0:\n",
    "            ST.at['RH WC Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 0)/len(first_trip)\n",
    "            ST.at['RH WC Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 0)/len(first_trip)\n",
    "            ST.at['RH WC not Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 1)/len(first_trip)\n",
    "            ST.at['RH WC not Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 1)/len(first_trip)\n",
    "    \n",
    "    return ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7aaaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  s3://beam-outputs/output/newyork/new-york-300k-calibration-7__2022-06-25_17-40-03_aui/ITERS/it.10/10.events.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2317/3282278865.py:9: DtypeWarning: Columns (0,5,6,8,10,13,14,15,16,18,20,23,24,25,26,32,39,44,47,55,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(directory, chunksize=2500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916271 : len chunk PT\n",
      "828519 : after filtering zero-length PT\n",
      "409535 : len chunk PEV\n",
      "320120 : after filtering drivers\n",
      "251296 : len chunk PLV\n",
      "251296 : after filtering drivers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2317/3282278865.py:9: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(directory, chunksize=2500000, nrows = nrows):\n"
     ]
    }
   ],
   "source": [
    "ST = pd.DataFrame()\n",
    "\n",
    "for data_name, name, plan_name in zip(data_names, names, plan_names):\n",
    "    \n",
    "    MCs = []\n",
    "    PTs = []\n",
    "    PEVs = []\n",
    "    PLVs = []\n",
    "    MCs, PTs, PEVs, PLVs, RPs  = readEvents(fp+data_name)\n",
    "    MCs, PTs, PEVs, PLVs = fixData(MCs, PTs, PEVs, PLVs, len_id_transit)\n",
    "    trips, activities, personToTripDepartures, is_leg_mode = processPlans(fp+plan_name)\n",
    "    PtoPTss = personToPathTraversal(PTs,PEVs,PLVs,personToTripDepartures)\n",
    "    codes = [0,1,2,3,4,5,6,7,8] \n",
    "    transitCompanies = PTs['vehicle2'][PTs['is_transit']>0].value_counts().keys()\n",
    "    \n",
    "    ST = SummaryTable(ST, data_name, name, plan_name, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss, codes, transitCompanies)\n",
    "    \n",
    "    print('Total Time', time.time()-start)\n",
    "    start = time.time()\n",
    "    print(ST[-6:],'Number of attributes',len(ST))\n",
    "    ST.to_csv(fp_res+output_nm)\n",
    "    \n",
    "ST['code'] = range(len(ST[ST.keys()[0]]))\n",
    "print(ST[-6:],'Number of attributes',len(ST))\n",
    "ST.to_csv(fp_res+output_nm)\n",
    "\n",
    "end = time.time()\n",
    "print('Total time',end- start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cd211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bb2e4-93c4-4aaf-9517-c290020515cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "\n",
    "ST2 = pd.DataFrame()\n",
    "# ST = pd.read_csv('outputs/SummaryTable_NYC_baseline.csv')\n",
    "shares_pop = [\n",
    "                # 0.33, 0.33,0.33,\n",
    "                0.0295,0.0295,\n",
    "    # 0.0295,0.0295,0.0295,0.0295,0.0295,\n",
    "                # 0.04425,0.04425,0.04425,\n",
    "                    # 0.1,0.1,\n",
    "                # 0.1,0.1,0.1,0.1,0.1,\n",
    "                # 0.1,0.1,0.1\n",
    "                ]\n",
    "\n",
    "\n",
    "for name, share_pop in zip(names,shares_pop):\n",
    "    \n",
    "    ST2.at['Original Population share', name] = share_pop\n",
    "    \n",
    "    ST2.at['Scaled Total Simulated Agents', name] = ST.at['Simulated Agents ', name]/share_pop\n",
    "    \n",
    "\n",
    "    ST2.at['Total Trips Estimated per Agent in a Day', name] = ST.at['Trips per Agent AV ', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Trips Estimated in a Day', name] = ST.at['Trips per Agent AV ', name]*ST.at['Simulated Agents ', name]/share_pop\n",
    "\n",
    "    if is_leg_mode:\n",
    "\n",
    "        ST2.at['Scaled Total Estimated Walk-Transit Trips in a Day', name] = ST.at['Trip Est Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Replanned Walk-Transit Trips in a Day', name] = ST.at['Trip Replan Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Modechoice Walk-Transit Trips in a Day', name] = ST.at['Trip Mode Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Share Estimated Walk-Transit Trips in a Day', name] = ST.at['Trip Est Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['Share Replanned Walk-Transit Trips in a Day', name] = ST.at['Trip Replan Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['Share Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Share Walk-Transit', name]\n",
    "    ST2.at['Share Executed Bike-Transit Trips in a Day', name] = ST.at['Trip Exec Share Bike-Transit', name]\n",
    "    ST2.at['Share Executed Ride Hail-Transit Trips in a Day', name] = ST.at['Trip Exec Share Ride Hail-Transit', name]\n",
    "    ST2.at['Share Executed Drive-Transit Trips in a Day', name] = ST.at['Trip Exec Share Drive-Transit', name]\n",
    "    ST2.at['Share Executed Transit Related Trips in a Day', name] = (ST.at['Trip Exec Share Walk-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Drive-Transit', name])\n",
    "    ST2.at['Share Executed Bike Trips in a Day', name] = ST.at['Trip Exec Share Bike', name]\n",
    "    ST2.at['Share Executed Car Trips in a Day', name] = ST.at['Trip Exec Share Car', name]\n",
    "    ST2.at['Share Executed Ride Hail Trips in a Day', name] = (ST.at['Trip Exec Share Ride Hail', name] +\n",
    "                                                            ST.at['Trip Exec Share Ride Hail Pooled', name])\n",
    "    ST2.at['Share Executed Walk Trips in a Day', name] = ST.at['Trip Exec Share Walk', name]\n",
    "    ST2.at['Share Executed Other Trips in a Day', name] = 1-(ST.at['Trip Exec Share Walk-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Drive-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike', name] +\n",
    "                                                                    ST.at['Trip Exec Share Car', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail Pooled', name] +\n",
    "                                                                    ST.at['Trip Exec Share Walk', name])\n",
    "\n",
    "\n",
    "    ST2.at['Share Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['AV Transit Transfers per trip', name] = ST.at['Transit Transfer per trip AV', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled MTA BUS Ridership (with transfers)', name] = (ST.at['Ridership MTA_Brookl', name]+\n",
    "                                                             ST.at['Ridership MTA_Bronx_', name]+\n",
    "                                                             ST.at['Ridership MTA_Queens', name]+\n",
    "                                                             ST.at['Ridership MTA_Staten', name]+\n",
    "                                                             ST.at['Ridership MTA_Manhat', name]+\n",
    "                                                             ST.at['Ridership NYC_Bus_Co', name])/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled MTA SUB Ridership (with transfers)', name] = ST.at['Ridership NYC_Subway', name]/share_pop\n",
    "    \n",
    "    ST2.at['Scaled MTA SUB Ridership (without transfers)', name] = ST.at['Ridership NYC Subway Without Transfers', name]/share_pop\n",
    "    \n",
    "    ST2.at['Subway vs Bus', name] = ST2.at['Scaled MTA SUB Ridership (without transfers)', name]/ST2.at['Scaled MTA BUS Ridership (with transfers)', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Metro North Ridership (with transfers)', name] = ST.at['Ridership Metro-Nort', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled LIRR Ridership (with transfers)', name] = ST.at['Ridership Long_Islan', name]/share_pop\n",
    "    \n",
    "    ST2.at['Scaled PATH Ridership (with transfers)', name] = ST.at['Ridership 151_631:t_', name]/share_pop\n",
    "    \n",
    "    ST2.at['Scaled NJ BUS Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Bus', name]/share_pop\n",
    "    ST2.at['Scaled NJ RAIL Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Rail', name]/share_pop\n",
    "    ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Light Rail', name]/share_pop\n",
    "    \n",
    "    \n",
    "ST2.at['Share Executed Transit Related Trips in a Day', 'Target'] = 'NHTS is 16.6%'\n",
    "ST2.at['Share Executed Bike Trips in a Day', 'Target'] = 'NHTS is 1.0%'\n",
    "ST2.at['Share Executed Car Trips in a Day', 'Target'] = 'NHTS is 53.9%'\n",
    "ST2.at['Share Executed Walk Trips in a Day', 'Target'] = 'NHTS is 26.1%'\n",
    "ST2.at['Share Executed Ride Hail Trips in a Day', 'Target'] = 'NHTS is 1.8%'\n",
    "ST2.at['Share Executed Other Trips in a Day', 'Target'] = 'NHTS is 0.6%'\n",
    "\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target'] = '≈2.2M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target'] = '≈5.4M'\n",
    "ST2.at['Subway vs Bus', 'Target'] = '≈2.5'\n",
    "ST2.at['Scaled Metro North Ridership (with transfers)', 'Target'] = '≈0.2M'\n",
    "ST2.at['Scaled LIRR Ridership (with transfers)', 'Target'] = '≈0.25M'\n",
    "    \n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target'] = '297k'\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target'] =  '451k'\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target'] =  '127k'\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target'] =  '14k'\n",
    "\n",
    "    \n",
    "ST2.to_csv('outputs/validationNYC.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ec296-63d0-47fd-876d-db15f2ae3b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7b50c-ee55-4dd7-96d9-7757d9091dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be483f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
