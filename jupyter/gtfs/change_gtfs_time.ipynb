{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954cad6-9adc-49a4-8d11-28dd898b6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import zlib\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def delete_folder_with_content(folder_to_delete):\n",
    "    # Try to remove the tree; if it fails, throw an error using try...except.\n",
    "    try:\n",
    "        shutil.rmtree(folder_to_delete)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    print(f\"Directory {folder_to_delete} deleted.\")\n",
    "\n",
    "\n",
    "def compress(in_file_names, in_files_path, out_zip_path):\n",
    "    \n",
    "    # Select the compression mode ZIP_DEFLATED for compression\n",
    "    # or zipfile.ZIP_STORED to just store the file\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "\n",
    "    # create the zip file first parameter path/name, second mode\n",
    "    zf = zipfile.ZipFile(out_zip_path, mode=\"w\")\n",
    "    try:\n",
    "        for file_name in in_file_names:\n",
    "            # Add file to the zip file\n",
    "            # first parameter file to zip, second filename in zip\n",
    "            zf.write(in_files_path + '/' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"An error occurred\")\n",
    "    finally:\n",
    "        # Don't forget to close the file!\n",
    "        zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857d738-ee0b-431b-82fc-10ef949efac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base variables\n",
    "\n",
    "# suffix to be added to new archives after changing\n",
    "archive_suffix_for_changed_gtfs = '.scaled_to_2017-09-18'\n",
    "\n",
    "# the date used as base for changes, need to be picked with regards to date configured in BEAM\n",
    "base_date = pd.to_datetime(\"2017-09-18\", format='%Y-%m-%d')\n",
    "# the timezone should be the same as the one configured in BEAM\n",
    "base_timezone = 'Etc/GMT+7'\n",
    "\n",
    "\n",
    "base_date, base_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd249d93-7a13-4dcc-9cae-4f07aec517f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for all gtfs archives in the specified folder\n",
    "\n",
    "gtfs_zip_files_location = \"../local_files/GTFS\"\n",
    "gtfs_archives = []\n",
    "\n",
    "# traverse all files and pick zip archives for further processing\n",
    "# excluding already changed archives\n",
    "for (dir_name, child_folders, files) in os.walk(gtfs_zip_files_location):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip') and archive_suffix_for_changed_gtfs not in file:\n",
    "            gtfs_archive = f'{gtfs_zip_files_location}/{file}'\n",
    "            gtfs_archives.append(gtfs_archive)\n",
    "\n",
    "gtfs_archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89185dc9-2c2c-4789-b22b-3979aaf74ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking found gtfs archives\n",
    "\n",
    "for gtfs_archive in gtfs_archives:\n",
    "\n",
    "    gtfs_unpacked = f\"{gtfs_archive}.unpacked\"\n",
    "\n",
    "    # making sure there is an empty folder to unpack\n",
    "    if os.path.isdir(gtfs_unpacked):\n",
    "        delete_folder_with_content(gtfs_unpacked)\n",
    "        \n",
    "    Path(gtfs_unpacked).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # unpack files\n",
    "    with zipfile.ZipFile(gtfs_archive, 'r') as zip_ref:\n",
    "        zip_ref.extractall(gtfs_unpacked)\n",
    "    \n",
    "    print(f\"GTFS archive {gtfs_unpacked} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ae6a2-64d5-4ebd-8688-5cfc97a9228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing date in all previously found gtfs archives\n",
    "\n",
    "for gtfs_archive in gtfs_archives:\n",
    "    gtfs_unpacked = f\"{gtfs_archive}.unpacked\"\n",
    "\n",
    "    # changing calendar dates\n",
    "    path_to_file = f'{gtfs_unpacked}/calendar.txt'\n",
    "    df = pd.read_csv(path_to_file, parse_dates=['start_date', 'end_date'])\n",
    "    min_date = df['start_date'].min()\n",
    "    df['start_date'] = df['start_date'] - min_date + base_date\n",
    "    df['end_date'] = df['end_date'] - min_date + base_date\n",
    "    df.to_csv(path_to_file, header=True, index=False, sep=',', quoting=csv.QUOTE_ALL, date_format='%Y%m%d')\n",
    "\n",
    "\n",
    "    # changing calendar_dates dates\n",
    "    path_to_file = f'{gtfs_unpacked}/calendar_dates.txt'\n",
    "    df = pd.read_csv(path_to_file, parse_dates=['date'])\n",
    "    df['date'] = df['date'] - min_date + base_date\n",
    "    df.to_csv(path_to_file, header=True, index=False, sep=',', quoting=csv.QUOTE_ALL, date_format='%Y%m%d')\n",
    "\n",
    "\n",
    "    # changing agency time zone\n",
    "    path_to_file = f'{gtfs_unpacked}/agency.txt'\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    df['agency_timezone'] = base_timezone\n",
    "    df.to_csv(path_to_file, header=True, index=False, sep=',', quoting=csv.QUOTE_ALL, date_format='%Y%m%d')\n",
    "    \n",
    "    print(f\"GTFS archive '{gtfs_archive}' processed\")\n",
    "    print()\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4097d-641d-499a-b194-2613134e51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack changed on previous step files into new GTFS archive\n",
    "\n",
    "for gtfs_archive in gtfs_archives:\n",
    "    gtfs_unpacked = f\"{gtfs_archive}.unpacked\"\n",
    "\n",
    "    for (dir_name, child_folders, files) in os.walk(gtfs_unpacked):\n",
    "        if 'agency.txt' in files:\n",
    "            out_archive_path = gtfs_archive.split('.zip')[0] + f'{archive_suffix_for_changed_gtfs}.zip'\n",
    "            if os.path.isfile(out_archive_path):\n",
    "                print(f\"Pre-existing '{out_archive_path}' deleted.\")\n",
    "                os.remove(out_archive_path)\n",
    "\n",
    "            compress(files, gtfs_unpacked, out_archive_path)\n",
    "            print(f\"Archive '{out_archive_path}' created.\")\n",
    "\n",
    "            delete_folder_with_content(gtfs_unpacked)\n",
    "            print()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107829e-f570-4578-83b3-ae722acad67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to view files during intermediate steps, not required to be run\n",
    "for gtfs_archive in gtfs_archives:\n",
    "\n",
    "    gtfs_unpacked = f\"{gtfs_archive}.unpacked\"\n",
    "\n",
    "    path_to_unpacked_archive = gtfs_unpacked\n",
    "\n",
    "    for (dir_name, child_folders, files) in os.walk(path_to_unpacked_archive):\n",
    "        if 'agency.txt' in files:\n",
    "            for file in files:\n",
    "                full_path = f'{path_to_unpacked_archive}/{file}'\n",
    "                df = pd.read_csv(full_path)\n",
    "                display(full_path, f'with size {len(df)}', df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59ce9a-7f23-4880-80b6-aed4c892947e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2d8d7-065e-4cab-a0ec-1ee037ed658c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
