{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a368145-a6f7-47c0-889b-096fc9f9ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90da842-b59f-4717-881d-60ac1aebc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading exported csv\n",
    "\n",
    "# to get csv - save 'BEAM Deploy Status and Run Data' as csv\n",
    "# if there is not enough permissions - save a copy and then save as csv\n",
    "\n",
    "local_path = '../local_files/latest_all_runs.csv'\n",
    "data = pd.read_csv(local_path, parse_dates=['Time'])\n",
    "data['unique_key'] = data.apply(lambda r: f\"{r['Host name']}|{r['Run Name']}|{r['Batch']}\", axis=1)\n",
    "\n",
    "# using only runs from specific data \n",
    "min_time = pd.to_datetime(\"2022-02-01\") # yyyy-mm-dd\n",
    "max_time = pd.to_datetime(\"2023-02-01\") # data['Time'].max()\n",
    "data = data[(data['Time'] > min_time) & (data['Time'] < max_time)].copy()\n",
    "\n",
    "print(f\"there are roughly {len(data) // 2} runs from {data['Time'].min().strftime('%Y-%m-%d')} to {data['Time'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"the latest run is from {data['Time'].max()}\")\n",
    "\n",
    "data['Month Period'] = data['Time'].dt.strftime('%Y-%m')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddba22a-3f5a-4b74-8c64-e6dd7b2371c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting data frame with each row as one simulation\n",
    "\n",
    "take_first_columns = ['Run Name','Month Period','Branch','Instance type']\n",
    "\n",
    "df = data.groupby(\"unique_key\").agg(list)\n",
    "for col in take_first_columns:\n",
    "    df[col] = df.apply(lambda r: r[col][0], axis=1)\n",
    "\n",
    "df['Time Start'] = df.apply(lambda r: r['Time'][0], axis=1)\n",
    "df['Time Stop'] = df.apply(lambda r: r['Time'][-1], axis=1)\n",
    "df['Status'] = df.apply(lambda r: r['Status'][-1], axis=1)\n",
    "\n",
    "all_columns = set(df.columns)\n",
    "taken_columns = take_first_columns + ['Time Start', 'Time Stop', 'Status', 'Time']\n",
    "\n",
    "df = df[taken_columns].copy()\n",
    "\n",
    "removed_columns = list(sorted(all_columns - set(taken_columns)))\n",
    "half_len = int(len(removed_columns)/2)\n",
    "print(f\"removed columns: {removed_columns}\")\n",
    "\n",
    "# fix for some wierd shift in the spreadsheet for few rows\n",
    "for v in ['ec2-18-221-208-40.us-east-2.compute.amazonaws.com',\n",
    "          'ec2-3-144-69-95.us-east-2.compute.amazonaws.com',\n",
    "          'ec2-52-15-53-101.us-east-2.compute.amazonaws.com']:\n",
    "    df.replace(to_replace=v, value='r5d.24xlarge', inplace=True)\n",
    "\n",
    "df['duration_hours'] = (df['Time Stop'] - df['Time Start']).astype('timedelta64[h]')\n",
    "print(f\"duration in hours total: {df['duration_hours'].sum()}\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3230f9-5cf8-417f-9b11-1f85b1f265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_to_price = {\n",
    "    'c5d.24xlarge' : 4.608,\n",
    "    'c6a.24xlarge' : 3.672,\n",
    "    'hpc6a.48xlarge' : 2.88,\n",
    "    'm4.16xlarge' : 3.2,\n",
    "    'm5.12xlarge' : 2.304,\n",
    "    'm5.24xlarge' : 4.608,\n",
    "    'm5d.24xlarge' : 5.424,\n",
    "    'r5.24xlarge' : 6.048,\n",
    "    'r5.2xlarge' : 0.504,\n",
    "    'r5.4xlarge' : 1.008,\n",
    "    'r5.8xlarge' : 2.016,\n",
    "    'r5.large' : 0.126,\n",
    "    'r5.xlarge' : 0.252,\n",
    "    'r5d.12xlarge' : 3.456,\n",
    "    'r5d.16xlarge' : 4.608,\n",
    "    'r5d.24xlarge' : 6.912,\n",
    "    't2.medium' : 0.0464,\n",
    "    't2.small': 0.023,\n",
    "    'c5.18xlarge': 3.06,\n",
    "    'c5.9xlarge': 1.53,\n",
    "    'c5d.4xlarge': 0.768,\n",
    "    'm5d.12xlarge': 2.712,\n",
    "    'r5.12xlarge': 3.024,\n",
    "    'r5a.16xlarge': 3.616,\n",
    "    'r5a.4xlarge': 0.904,\n",
    "    'r5d.2xlarge': 0.576,\n",
    "    'r5d.4xlarge': 1.152,\n",
    "    'z1d.12xlarge': 4.464,\n",
    "    'n2d-standard-2': 0.0,    # a google cloud instance, actually 0.084492, but we are interested in AWS only,\n",
    "    'n2d-standard-4': 0.0,    # a google cloud instance, actually 0.168984, but we are interested in AWS only,\n",
    "    'n2d-standard-64' : 0.0,  # a google cloud instance, ignoring for now\n",
    "}\n",
    "\n",
    "instance_to_number_of_cores = {\n",
    "    'c5d.24xlarge': 96,\n",
    "    'c6a.24xlarge': 96,\n",
    "    'hpc6a.48xlarge': 96,\n",
    "    'm5.12xlarge': 48,\n",
    "    'r5.24xlarge': 96,\n",
    "    'r5.2xlarge': 8,\n",
    "    'r5.4xlarge': 16,\n",
    "    'r5.8xlarge': 32,\n",
    "    'r5.large': 2,\n",
    "    'r5.xlarge': 4,\n",
    "    'r5d.12xlarge': 48,\n",
    "    'r5d.16xlarge': 64,\n",
    "    'r5d.24xlarge': 96,\n",
    "    't2.medium': 2,\n",
    "    't2.small': 1,\n",
    "    'c5.18xlarge': 72,\n",
    "    'c5.9xlarge': 36,\n",
    "    'c5d.4xlarge': 16,\n",
    "    'm4.16xlarge': 64,\n",
    "    'm5.24xlarge': 96,\n",
    "    'm5d.12xlarge': 48,\n",
    "    'm5d.24xlarge': 96,\n",
    "    'r5.12xlarge': 48,\n",
    "    'r5a.16xlarge': 64,\n",
    "    'r5a.4xlarge': 16,\n",
    "    'r5d.2xlarge': 8,\n",
    "    'r5d.4xlarge': 16,\n",
    "    'z1d.12xlarge': 48,\n",
    "    'n2d-standard-2': 0,     # a google cloud instance, ignoring for now\n",
    "    'n2d-standard-4': 0,     # a google cloud instance, ignoring for now\n",
    "    'n2d-standard-64' : 0,   # a google cloud instance, ignoring for now\n",
    "}\n",
    "\n",
    "\"done\"\n",
    "\n",
    "inst2price2cores = []\n",
    "\n",
    "for inst_type in instance_to_price.keys():\n",
    "    price = instance_to_price[inst_type]\n",
    "    cores = instance_to_number_of_cores[inst_type]\n",
    "    inst2price2cores.append((inst_type, price, cores))\n",
    "\n",
    "aws_info_df = pd.DataFrame(inst2price2cores, columns=['Instance', 'Price', 'Number of Cores'])\n",
    "aws_info_df['price_to_core'] = aws_info_df['Price'] / aws_info_df['Number of Cores']\n",
    "aws_info_df.sort_values('price_to_core').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fb00d-5a15-4167-a062-58c67a32340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating a price in USD of each simulation\n",
    "\n",
    "missing_instance_types = set()\n",
    "def get_instance_hour_cost(row):\n",
    "    instance_type = row['Instance type']\n",
    "    if instance_type in instance_to_price :\n",
    "        return instance_to_price[instance_type]\n",
    "\n",
    "    missing_instance_types.add(instance_type)\n",
    "    return 0.0\n",
    "\n",
    "df['aws_instance_hour_cost'] = df.apply(get_instance_hour_cost, axis=1)\n",
    "\n",
    "if len(missing_instance_types) > 0:\n",
    "    print(f\"Can't find price for {len(missing_instance_types)} instance types.\")\n",
    "    for missing_instance in sorted(missing_instance_types):\n",
    "        print(f\"'{missing_instance}': ,\")\n",
    "\n",
    "\n",
    "missing_instance_types = set()\n",
    "def get_number_of_cores(row):\n",
    "    instance_type = row['Instance type']\n",
    "    if instance_type in instance_to_number_of_cores:\n",
    "        return instance_to_number_of_cores[instance_type]\n",
    "\n",
    "    missing_instance_types.add(instance_type)\n",
    "    return 0\n",
    "\n",
    "df['aws_instance_number_of_cores'] = df.apply(get_number_of_cores, axis=1)\n",
    "\n",
    "if len(missing_instance_types) > 0:\n",
    "    print(f\"Can't find number of cores for {len(missing_instance_types)} instance types.\")\n",
    "    for missing_instance in sorted(missing_instance_types):\n",
    "        print(f\"'{missing_instance}': ,\")\n",
    "\n",
    "def get_cores_hours(row):\n",
    "    number_of_cores = row['aws_instance_number_of_cores']\n",
    "    number_of_hours = row['duration_hours']\n",
    "    return number_of_cores * number_of_hours\n",
    "\n",
    "df['aws_corehours_per_simulation'] = df.apply(get_cores_hours, axis=1)\n",
    "    \n",
    "df['cost'] = df['duration_hours'] * df['aws_instance_hour_cost']\n",
    "total_cost = int(df['cost'].sum())\n",
    "\n",
    "def print_total_info(total_cost_fixed=None):\n",
    "    print(f\"There are {len(df)} simulations from {data['Time'].min().strftime('%Y-%m-%d')} to {data['Time'].max().strftime('%Y-%m-%d')}\")\n",
    "    if total_cost_fixed:\n",
    "        print(f\"The total cost of all instances time is ${total_cost_fixed}\")\n",
    "    else:\n",
    "        print(f\"The total cost of all instances time is ${total_cost}\")\n",
    "\n",
    "print_total_info()\n",
    "\n",
    "print(f\"aws core hours: {df['aws_corehours_per_simulation'].sum()}\")\n",
    "print(f\"total cost: {df['cost'].sum()}\")\n",
    "df.groupby('Month Period').agg({'cost':['sum','count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66382a-4090-4da7-9c3c-8b26a4e35ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying 'project' to the list of simulations based on simulation name and|or git branch name\n",
    "\n",
    "\n",
    "def get_branch_owner(row):\n",
    "    branch = row['Branch'].split('/')\n",
    "    if len(branch) > 1:\n",
    "        return branch[0]\n",
    "    return branch\n",
    "\n",
    "\n",
    "other_projects = set()\n",
    "\n",
    "def get_project(row):\n",
    "    run_name = row['Run Name']\n",
    "    branch_owner = get_branch_owner(row)\n",
    "    project = f\"{branch_owner} | {run_name}\".lower()\n",
    "\n",
    "    if 'new-york' in project:\n",
    "        return \"NYC\"\n",
    "    if 'freight' in project:\n",
    "        return \"Freight\"\n",
    "    if 'gemini' in project:\n",
    "        return \"Gemini\"\n",
    "    if 'micro-mobility' in project or 'micromobility' in project:\n",
    "        return \"Micro-Mobility\"\n",
    "    if 'shared' in project:\n",
    "        return \"Shared Fleet\"\n",
    "    if 'profiling' in project:\n",
    "        return \"CPU profiling\"\n",
    "    \n",
    "    other_projects.add(project)\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "df[\"project\"] = df.apply(get_project, axis=1)\n",
    "list_of_all_projects = sorted(list(df['project'].unique()))\n",
    "print(f\"there are {len(list_of_all_projects)} projects ({len(other_projects)} runs classified as 'other'):\")\n",
    "for project_name in list_of_all_projects:\n",
    "    print(f\"\\t{project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab32b6e-6a2e-439b-b4ec-c7f9f188019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### processing simulations in unknown state, i.e. with 'Run Started' status\n",
    "def get_fixed_status(row):\n",
    "    status = row[\"Status\"]\n",
    "    if status != 'Run Started':\n",
    "        return status\n",
    "    inactive_time = pd.Timestamp.now() - row['Time Start']\n",
    "    if inactive_time.days > 2:\n",
    "        return 'Run Failed'\n",
    "    return 'Maybe Running'\n",
    "\n",
    "df['Status Fixed'] = df.apply(get_fixed_status, axis=1)\n",
    "\n",
    "### grouping dataframe by project\n",
    "df_grouped = df.groupby(\"project\").agg(list).reset_index()\n",
    "\n",
    "df_grouped[\"Duration Hours Total\"] = df_grouped.apply(lambda r: sum(r['duration_hours']), axis=1)\n",
    "df_grouped[\"Instance time cost\"] = df_grouped.apply(lambda r: sum(r['cost']), axis=1)\n",
    "df_grouped[\"Fraction of total cost\"] = df_grouped.apply(lambda r: r['Instance time cost'] / total_cost, axis=1)\n",
    "df_grouped[\"AWS Core-Hours\"] = df_grouped.apply(lambda r: sum(r['aws_corehours_per_simulation']), axis=1)\n",
    "df_grouped = df_grouped.sort_values(\"Fraction of total cost\", ascending=False).reset_index()\n",
    "\n",
    "\n",
    "def failed_runs_time_cost(project_row):\n",
    "    runs_state = project_row['Status Fixed']\n",
    "    runs_cost = project_row['cost']\n",
    "    failed_cost_sum = 0.0\n",
    "    for (state, cost) in zip(runs_state, runs_cost):\n",
    "        if state == 'Run Failed':\n",
    "            failed_cost_sum += cost\n",
    "    return failed_cost_sum\n",
    "\n",
    "df_grouped[\"Failed runs time cost\"] = df_grouped.apply(failed_runs_time_cost, axis=1)\n",
    "\n",
    "\n",
    "df_grouped[\"Instance types\"] = df_grouped.apply(lambda r: list(set(r[\"Instance type\"])), axis=1)\n",
    "\n",
    "# 'Run Failed', 'Run Completed', 'Run Started', 'Unable to start'\n",
    "df_grouped[\"Failed runs\"] = df_grouped.apply(lambda r: r['Status Fixed'].count('Run Failed')+r['Status'].count('Unable to start'), axis=1)\n",
    "df_grouped[\"Completed runs\"] = df_grouped.apply(lambda r: r['Status Fixed'].count('Run Completed'), axis=1)\n",
    "df_grouped[\"Maybe still running\"] = df_grouped.apply(lambda r: r['Status Fixed'].count('Maybe Running'), axis=1)\n",
    "\n",
    "\n",
    "columns_with_numbers = [\"Instance time cost\", \"Failed runs time cost\", \"Fraction of total cost\", \n",
    "                        \"Completed runs\", \"Failed runs\", \"Maybe still running\", \n",
    "                        \"AWS Core-Hours\", \"Duration Hours Total\"]\n",
    "df_grouped.loc[\"Total\"] = df_grouped[columns_with_numbers].sum()\n",
    "\n",
    "selected_columns = [\"project\", \"Instance types\"] + columns_with_numbers\n",
    "\n",
    "print_total_info()\n",
    "df_grouped[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bed34-ef6f-45d2-ba56-bb28398a17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### a short version\n",
    "\n",
    "print_total_info(total_cost_fixed=\"???\")\n",
    "df_grouped[[\"project\", \"Fraction of total cost\", \"AWS Core-Hours\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6691f2-5e1c-48b1-b2fd-ed1bc10ddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### grouped by instance type\n",
    "\n",
    "df_grouped_by_instance = df.groupby('Instance type').agg(list).reset_index()\n",
    "\n",
    "\n",
    "df_grouped_by_instance['cost_per_instance_type'] = df_grouped_by_instance.apply(lambda r: sum(r['cost']), axis=1)\n",
    "total_cost = df_grouped_by_instance['cost_per_instance_type'].sum()\n",
    "df_grouped_by_instance['Fraction of Total Cost'] = df_grouped_by_instance.apply(lambda r: r['cost_per_instance_type'] / total_cost, axis=1)\n",
    "\n",
    "df_grouped_by_instance.sort_values('Fraction of Total Cost', ascending=False, inplace=True)\n",
    "df_grouped_by_instance.reset_index(inplace=True)\n",
    "\n",
    "# print_total_info()\n",
    "df_grouped_by_instance[['Instance type', 'Fraction of Total Cost']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d6079-1d88-41d5-ae74-52bad734cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_instance.groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b514d71-46f1-4861-be1b-cd9d77ec618c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30b6ab-e1da-45af-8adb-fd0bb72da458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade957f3-ddc7-4db9-8374-913a2e2f5c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
