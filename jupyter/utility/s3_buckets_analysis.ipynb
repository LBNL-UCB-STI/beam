{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb71d281-6ddf-44ff-b492-f1fb2eebbca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 is already installed\n"
     ]
    }
   ],
   "source": [
    "# %pip install boto3\n",
    "import pip\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f'{package} is already installed')\n",
    "    except ImportError:\n",
    "        print(f'Installing {package}')\n",
    "        pip.main(['install', package])\n",
    "\n",
    "\n",
    "import_or_install(\"boto3\")\n",
    "import boto3\n",
    "\n",
    "aws_access_key_id = \"\"\n",
    "aws_secret_access_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cc4e8c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>output/beamville/beamville-urbansimv2_input__2...</td>\n",
       "      <td>2022-12-03 08:20:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output/beamville/beamville-urbansimv2_input__2...</td>\n",
       "      <td>2023-01-15 07:14:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>output/beamville/beamville-urbansimv2_input__2...</td>\n",
       "      <td>2023-01-15 07:16:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>output/beamville/beamville-xml__2019-10-19_17-...</td>\n",
       "      <td>2019-10-19 17:12:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>output/beamville/beamville-xml__2019-10-20_08-...</td>\n",
       "      <td>2019-10-20 08:50:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>output/beamville/beamville__2023-01-15_07-03-0...</td>\n",
       "      <td>2023-01-15 07:04:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>output/beamville/beamville__2023-01-15_07-13-2...</td>\n",
       "      <td>2023-01-15 07:14:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>output/beamville/beamville__2023-01-15_07-14-3...</td>\n",
       "      <td>2023-01-15 07:16:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>output/beamville/beamville__2023-02-08_19-12-3...</td>\n",
       "      <td>2023-02-08 19:14:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>output/beamville/beamville__2023-03-25_15-23-4...</td>\n",
       "      <td>2023-03-25 15:25:48+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "0    output/beamville/beamville-urbansimv2_input__2...   \n",
       "1    output/beamville/beamville-urbansimv2_input__2...   \n",
       "2    output/beamville/beamville-urbansimv2_input__2...   \n",
       "3    output/beamville/beamville-xml__2019-10-19_17-...   \n",
       "4    output/beamville/beamville-xml__2019-10-20_08-...   \n",
       "..                                                 ...   \n",
       "117  output/beamville/beamville__2023-01-15_07-03-0...   \n",
       "118  output/beamville/beamville__2023-01-15_07-13-2...   \n",
       "119  output/beamville/beamville__2023-01-15_07-14-3...   \n",
       "120  output/beamville/beamville__2023-02-08_19-12-3...   \n",
       "121  output/beamville/beamville__2023-03-25_15-23-4...   \n",
       "\n",
       "                         date  \n",
       "0   2022-12-03 08:20:40+00:00  \n",
       "1   2023-01-15 07:14:15+00:00  \n",
       "2   2023-01-15 07:16:20+00:00  \n",
       "3   2019-10-19 17:12:28+00:00  \n",
       "4   2019-10-20 08:50:14+00:00  \n",
       "..                        ...  \n",
       "117 2023-01-15 07:04:43+00:00  \n",
       "118 2023-01-15 07:14:42+00:00  \n",
       "119 2023-01-15 07:16:10+00:00  \n",
       "120 2023-02-08 19:14:03+00:00  \n",
       "121 2023-03-25 15:25:48+00:00  \n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Searches for beam folders on S3 bucket and saves path/last_modified/size to a csv file (local_files dir)\n",
    "# using low level API to get only the first level of subfolders\n",
    "bucket_name = 'beam-outputs'\n",
    "search_prefix = 'output/beamville'\n",
    "\n",
    "s3 = boto3.resource('s3', aws_access_key_id=aws_access_key_id,\n",
    "                    aws_secret_access_key=aws_secret_access_key) if aws_access_key_id else boto3.resource('s3')\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PrefixContent:\n",
    "    prefix: str\n",
    "    objects: []\n",
    "    folders: []\n",
    "    last_modified: datetime\n",
    "@dataclass\n",
    "class BeamFolder:\n",
    "    path: str\n",
    "    last_modified: datetime\n",
    "\n",
    "\n",
    "def find_content(prefix: str):\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix, Delimiter=\"/\")\n",
    "    objects = []\n",
    "    folders = []\n",
    "    last_modified = None\n",
    "    for page in pages:\n",
    "        if \"Contents\" in page:\n",
    "            for obj in page[\"Contents\"]:\n",
    "                objects.append(obj[\"Key\"])\n",
    "                if not last_modified:\n",
    "                    last_modified = obj[\"LastModified\"]\n",
    "        if \"CommonPrefixes\" in page:\n",
    "            for obj in page[\"CommonPrefixes\"]:\n",
    "                folders.append(obj[\"Prefix\"])\n",
    "\n",
    "    return PrefixContent(prefix, objects, folders, last_modified)\n",
    "\n",
    "\n",
    "def find_beam_folders(prefix: str):\n",
    "    content = find_content(prefix)\n",
    "    if any(x for x in content.folders if x.endswith(\"/ITERS/\")) | any(\n",
    "            x for x in content.objects if x.endswith(\"/beamLog.out\")):\n",
    "        beam_folder = BeamFolder(content.prefix, content.last_modified)\n",
    "        print(beam_folder)\n",
    "        return [beam_folder]\n",
    "    else:\n",
    "        return [x for folder in content.folders for x in find_beam_folders(folder)]\n",
    "\n",
    "\n",
    "beam_folders = find_beam_folders(search_prefix)\n",
    "\n",
    "result = [[x.path, x.last_modified] for x in beam_folders]\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"path\", \"date\"])\n",
    "file_name = search_prefix.split('/')[-1] + \".csv\"\n",
    "docker_path = \"/home/jovyan/local_files\"\n",
    "dir_to_save = docker_path if os.path.isdir(docker_path) else \"../local_files\"\n",
    "\n",
    "display(df)\n",
    "df.to_csv(os.path.join(dir_to_save, file_name), index=False)\n",
    "\n",
    "\n",
    "# pages = paginator.paginate(Bucket=bucket_name, Prefix=search_prefix, Delimiter=\"/\")\n",
    "# for page in pages:\n",
    "#     print(\"Sub-folders:\", list(obj[\"Prefix\"] for obj in page[\"CommonPrefixes\"]))\n",
    "#     print(\"Objects:\", list(obj[\"Key\"] for obj in page[\"Contents\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3695b04",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving ['sfbay-smart-base__2019-05-22_22-09-53'] to archive/root\n",
      "Moving sfbay-smart-base__2019-05-22_22-09-53 to archive/root\n",
      "\n",
      "Moved sfbay-smart-base__2019-05-22_22-09-53\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# move s3 folders (read from a csv file) to some location within the same bucket\n",
    "bucket_name = 'beam-outputs'\n",
    "destination = \"archive/root\"\n",
    "file = \"../local_files/test_moved.csv\"\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "if destination.endswith(\"/\"): destination = destination[:-1]\n",
    "\n",
    "paths = pd.read_csv(file)['path'].tolist()\n",
    "\n",
    "print(f\"Moving {paths} to {destination}\")\n",
    "\n",
    "s3 = boto3.resource('s3', aws_access_key_id=aws_access_key_id,\n",
    "                    aws_secret_access_key=aws_secret_access_key) if aws_access_key_id else boto3.resource('s3')\n",
    "\n",
    "not_to_delete = pd.read_csv(\"../local_files/not_to_delete.csv\")['path'].tolist()\n",
    "\n",
    "for path in paths:\n",
    "    path = path.strip()\n",
    "    if path.endswith(\"/\"): path = path[:-1]\n",
    "    if path == \"\": continue\n",
    "    if any(x for x in not_to_delete if path.startswith(x)):\n",
    "        print(f\"NOT DELETE {path}\")\n",
    "        continue\n",
    "    print(f\"Moving {path} to {destination}\")\n",
    "\n",
    "    last_index = path.rfind('/')\n",
    "    outer_folder = path[0:last_index] if last_index >= 0 else \"\"\n",
    "    print(outer_folder)\n",
    "\n",
    "    def move_obj(obj_key):\n",
    "        copy_source = {'Bucket': bucket_name, 'Key': obj_key}\n",
    "        new_folder = obj_key[len(outer_folder):]\n",
    "        if  not new_folder.startswith(\"/\"):\n",
    "            new_folder = \"/\" + new_folder\n",
    "        new_key = destination + new_folder\n",
    "        # print(new_key)\n",
    "        s3.meta.client.copy(copy_source, bucket_name, new_key)\n",
    "        s3.meta.client.delete_object(Bucket=bucket_name, Key=obj_key)\n",
    "\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    object_keys = [obj.key for obj in bucket.objects.filter(Prefix=path)]\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as p:\n",
    "        p.map(move_obj, object_keys)\n",
    "\n",
    "    print(f\"Moved {path}\")\n",
    "\n",
    "print(f\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
