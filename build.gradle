import com.amazonaws.ClientConfiguration
import com.amazonaws.services.lambda.AWSLambda
import com.amazonaws.services.lambda.AWSLambdaClient
import com.amazonaws.services.lambda.model.InvocationType
import com.amazonaws.services.lambda.model.InvokeRequest
import com.amazonaws.services.lambda.model.LogType
import com.google.common.base.Charsets
import com.google.common.io.Files
import jp.classmethod.aws.gradle.lambda.AWSLambdaInvokeTask
import jp.classmethod.aws.gradle.lambda.AWSLambdaPluginExtension
import org.unbrokendome.gradle.plugins.helm.command.tasks.HelmInit
import org.unbrokendome.gradle.plugins.helm.command.tasks.HelmInstall

import java.lang.reflect.Field
import java.time.Instant
import java.time.LocalDateTime
import java.time.ZoneOffset
import java.time.format.DateTimeFormatter

import groovy.json.JsonSlurper


buildscript {
    repositories {
        jcenter()
        mavenLocal()
        mavenCentral()
        maven { url "https://plugins.gradle.org/m2/" }
    }
    dependencies {
        classpath group: 'kr.motd.gradle', name: 'sphinx-gradle-plugin', version: '1.0.3.Final'
        classpath "jp.classmethod.aws:gradle-aws-plugin:0.35"
        classpath "com.github.viswaramamoorthy:gradle-util-plugins:0.1.0-RELEASE"
        classpath 'cz.alenkacz:gradle-scalafmt:1.7.0'
        classpath 'com.bmuschko:gradle-docker-plugin:3.6.1'
        classpath 'com.github.jengelman.gradle.plugins:shadow:2.0.4'

    }
}

plugins {
    id "net.ltgt.apt" version "0.5"
    id "de.undercouch.download" version "3.2.0"
    id "org.scoverage" version "3.0.0"
    id 'org.ajoberstar.grgit' version '1.7.2'
    id 'maven-publish'
    id 'org.unbroken-dome.helm' version '0.3.0'
    id 'org.unbroken-dome.helm-commands' version '0.3.0'
    id 'org.unbroken-dome.helm-releases' version '0.3.0'
    id 'org.unbroken-dome.helm-publish' version '0.3.0'
}

//ext {
//    env = "beamville"
//}

apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'maven'
apply plugin: 'idea'
apply plugin: 'kr.motd.sphinx'
apply plugin: 'application'
apply plugin: 'ManifestClasspath'
apply plugin: 'scalafmt'
apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'com.bmuschko.docker-java-application'

group = 'beam'
version = '0.6.0'

description = """"""

sourceCompatibility = 1.8
targetCompatibility = 1.8

compileScala.options.encoding = 'UTF-8'
def scalaBinaryVersion = "2.12"
def akkaBinaryVersion = "2.5.22"
def circeBinaryVersion = "0.7.1"
def slf4jVersion = "1.7.25"
def kamonVersion = "0.6.7"
def tscfgVersion = "0.9.4"

sourceSets.main.scala.srcDirs = ["src/main/scala", "src/main/java"]
sourceSets.main.java.srcDirs = []

sourceSets.test.java.srcDirs = []
sourceSets.test.scala.srcDirs = ["src/test/scala", "src/test/java"]

sourceSets {
    main {
        resources {
            srcDir "src/main/resources"
        }
    }
    test {
        resources {
            srcDir "src/test/resources"
        }
    }
}

if (project.hasProperty('env')) {
    sourceSets {
        main {
            resources {
                srcDirs "test/input/" + project.getProperty('env')
            }
        }
    }
}

allprojects {
    repositories {
        maven { url 'http://download.osgeo.org/webdav/geotools/' }
        // maven { url "http://maven.geotoolkit.org/" }
        maven { url "https://repository.jboss.org/nexus/content/repositories/thirdparty-releases" }
        maven { url "http://central.maven.org/maven2" }
        maven { url "http://repo.maven.apache.org/maven2" }
        maven { url "http://download.osgeo.org/webdav/geotools" }
        maven { url "http://dl.bintray.com/matsim/matsim" }
        maven { url "http://maven.conveyal.com/" }
        maven { url "http://repo1.maven.org/maven2" }
        maven { url "http://download.java.net/maven/2/" }
        maven { url "http://people.apache.org/repo/m1-ibiblio-rsync-repository/org.apache.axis2/" }
        maven { url "http://dl.bintray.com/andimarek/graphql-java" }
        maven { url "http://maven.geo-solutions.it" }
        maven { url "http://dl.bintray.com/scalaz/releases" }
        mavenLocal()
        mavenCentral()
        jcenter()
        maven { url "http://nexus.onebusaway.org/content/groups/public/" }
        maven { url "https://jitpack.io" }
    }
}

dependencies {

    compile(group: 'com.github.LBNL-UCB-STI', name: 'beam-utilities', version: 'v0.2.3') {
        exclude group: 'com.github.LBNL-UCB-STI', module: 'r5'
    }
    
    ////////////////////////////
    // Java dependencies
    ////////////////////////////
    compile group: 'com.google.inject', name: 'guice', version: '4.1.0'
    compile group: 'com.google.inject.extensions', name: 'guice-assistedinject', version: '4.1.0'
    compile group: 'com.google.inject.extensions', name: 'guice-multibindings', version: '4.1.0'
    compile group: 'org.apache.commons', name: 'commons-collections4', version: '4.1'
    compile group: 'org.apache.commons', name: 'commons-math3', version: '3.5'
    compile group: 'org.apache.httpcomponents', name: 'fluent-hc', version: '4.5.2'

    // Apache 2.0
    compile group: 'com.univocity', name: 'univocity-parsers', version: '2.8.1'

    // LGPL
    compile group: 'org.geotools', name: 'gt-main', version: '13.0'
    compile group: 'org.geotools', name: 'gt-shapefile', version: '13.0'
    compile group: 'org.geotools', name: 'gt-referencing', version: '15.2'
    compile group: 'org.geotools', name: 'gt-epsg-wkt', version: '15.2'
    compile group: 'org.jfree', name: 'jfreechart', version: '1.0.14'

    compile group: 'com.fasterxml.jackson.core', name: 'jackson-core', version: '2.9.4'
    compile group: 'com.fasterxml.jackson.module', name: 'jackson-module-scala_2.12', version: '2.9.4'
    compile group: 'javax.inject', name: 'javax.inject', version: '1'
    compile group: 'jdom', name: 'jdom', version: '1.1'
    compile group: 'org.jdom', name: 'jdom2', version: '2.0.5'
    compile 'com.hubspot.jinjava:jinjava:2.0.5'
    compile group: 'org.yaml', name: 'snakeyaml', version: '1.18'

    compile group: 'commons-io', name: 'commons-io', version: '2.5'
    compile 'net.sf.supercsv:super-csv:2.4.0'
    compile 'org.reflections:reflections:0.9.10'
    compile group: 'javax.annotation', name: 'javax.annotation-api', version: '1.2-b01'
    compile group: 'com.github.stephenc.eaio-uuid', name: "uuid", version: "3.4.0"

    compile "org.jgrapht:jgrapht-core:1.3.0"

    // GPLv3
    compile group: 'org.matsim.contrib', name: 'multimodal', version: '0.10.0'
    compile group: 'org.matsim.contrib', name: 'bicycle', version: '0.10.0'

    compile(group: 'org.matsim.contrib', name: 'decongestion', version: '0.11.0-2018w44') {
        exclude group: 'org.matsim', module: 'matsim'
    }

    compile(group: 'com.github.wrashid.matsim', name: 'matsim', version: '0.10.1-beam-6') {
        exclude group: 'log4j', module: 'log4j'
    }

    compile "org.slf4j:slf4j-api:${slf4jVersion}"
    compile "ch.qos.logback:logback-classic:1.2.3"
    compile "com.typesafe.scala-logging:scala-logging_${scalaBinaryVersion}:3.9.0"
    compile "org.slf4j:log4j-over-slf4j:${slf4jVersion}"

    compile(group: 'com.github.michaz', name: 'r5', version: '3ab4fa04') {
        exclude group: 'ch.qos.logback', module: 'logback-classic'
        exclude group: 'org.slf4j', module: 'slf4j-simple'
    }

    compile "com.sigopt:sigopt-java:4.9.0"

    testCompile group: 'junit', name: 'junit', version: '4.8'
    testCompile group: 'org.mockito', name: 'mockito-inline', version: '2.27.0'
    testCompile group: "org.mockito", name: "mockito-core", version: "2.+"

    /////////////////////////////////
    // Scala dependencies
    /////////////////////////////////

    // CORE Scala //
    compile "org.scala-lang:scala-library:2.12.7"
    compile group: 'org.scala-lang.modules', name: "scala-xml_${scalaBinaryVersion}", version: '1.0.6'

    // NEEDED FOR USING REPL //
    compile "org.scala-lang:scala-compiler:2.12.7"

    // TEST Scala //
    testCompile group: 'org.scalatest', name: "scalatest_${scalaBinaryVersion}", version: '3.0.1'
    testRuntime "org.pegdown:pegdown:1.4.2" // HTML report for scalatest

    // 3rd Party Scala //

    compile group: 'org.jliszka', name: 'probability-monad_2.11', version: '1.0.1'

    // https://mvnrepository.com/artifact/com.beachape/enumeratum_2.12
    compile group: 'com.beachape', name: "enumeratum_${scalaBinaryVersion}", version: "1.5.12"
    // https://mvnrepository.com/artifact/com.beachape/enumeratum-circe_2.12
    compile group: 'com.beachape', name: "enumeratum-circe_${scalaBinaryVersion}", version: "1.5.14"

    compile "com.github.scopt:scopt_${scalaBinaryVersion}:3.7.0"
    compile "net.codingwell:scala-guice_${scalaBinaryVersion}:4.1.0"  // DI
    compile('com.github.carueda:tscfg:v' + tscfgVersion) { // config
        exclude group: 'org.scala-lang.modules', module: 'scala-xml_2.11'
    }
    // https://mvnrepository.com/artifact/io.circe/circe-core_2.12
    compile group: 'io.circe', name: "circe-core_${scalaBinaryVersion}", version: circeBinaryVersion
    // https://mvnrepository.com/artifact/io.circe/circe-generic_2.12
    compile group: 'io.circe', name: "circe-generic_${scalaBinaryVersion}", version: circeBinaryVersion
    // https://mvnrepository.com/artifact/io.circe/circe-parser_2.12
    compile group: 'io.circe', name: "circe-parser_${scalaBinaryVersion}", version: circeBinaryVersion

    compile group: 'com.typesafe.play', name: "play-json_${scalaBinaryVersion}", version: '2.6.3'
    compile (group: 'com.github.romix.akka', name: "akka-kryo-serialization_${scalaBinaryVersion}", version: '0.5.2') {
        exclude group: 'com.esotericsoftware', module: 'kryo'
    }
    compile group: 'com.esotericsoftware', name: 'kryo', version: '4.0.2'

    compile "com.github.vagmcs:optimus_${scalaBinaryVersion}:3.1.0"
    compile "com.github.vagmcs:optimus-solver-oj_${scalaBinaryVersion}:3.1.0"

    ////////////////////////////////////
    ///Performance Monitoring (Kamon)///
    ////////////////////////////////////

    compile("io.kamon:kamon-core_${scalaBinaryVersion}:${kamonVersion}")
    compile("io.kamon:kamon-scala_${scalaBinaryVersion}:${kamonVersion}")
    compile("io.kamon:kamon-akka-2.4_${scalaBinaryVersion}:${kamonVersion}")
    compile("io.kamon:kamon-statsd_${scalaBinaryVersion}:${kamonVersion}")
    compile "io.kamon:kamon-influxdb_${scalaBinaryVersion}:0.6.9"
    compile("io.kamon:kamon-log-reporter_${scalaBinaryVersion}:${kamonVersion}")

    /////////////
    // Akka Dependencies
    ////////////

    // CORE Akka //
    compile group: 'com.typesafe.akka', name: "akka-actor_${scalaBinaryVersion}", version: akkaBinaryVersion
    compile group: 'com.typesafe.akka', name: "akka-slf4j_${scalaBinaryVersion}", version: akkaBinaryVersion
//    compile group: 'com.typesafe.akka', name: "akka-persistence_${scalaBinaryVersion}", version: akkaBinaryVersion
//    compile group: 'com.typesafe.akka', name: "akka-remote_${scalaBinaryVersion}", version: akkaBinaryVersion
    compile group: 'com.typesafe.akka', name: "akka-cluster_${scalaBinaryVersion}", version: akkaBinaryVersion
    compile group: 'com.typesafe.akka', name: "akka-contrib_${scalaBinaryVersion}", version: akkaBinaryVersion
//    compile group: 'org.iq80.leveldb', name: 'leveldb', version: '0.9'

    compile group: 'com.typesafe.akka', name: "akka-http_${scalaBinaryVersion}", version: "10.1.8"
    compile group: 'de.heikoseeberger', name: "akka-http-circe_${scalaBinaryVersion}", version: "1.25.2"

    // TEST Akka //
    testCompile group: 'com.typesafe.akka', name: "akka-testkit_${scalaBinaryVersion}", version: akkaBinaryVersion

    // 3rd Party Akka //
    //compile group: 'org.iq80.leveldb', name: 'leveldb', version: '0.7'
//    compile group: 'org.fusesource.leveldbjni', name: 'leveldbjni-all', version: '1.8'
    //compile group: 'com.google.protobuf', name: 'protobuf-java', version: '2.5.0'

    scoverage "org.scoverage:scalac-scoverage-plugin_${scalaBinaryVersion}:1.3.1", "org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:1.3.1"

    compile 'org.apache.commons:commons-compress:1.18'

    def parquet = "1.10.0"
    compile group: 'org.apache.parquet', name: 'parquet-hadoop', version: parquet
    compile group: 'org.apache.parquet', name: 'parquet-avro', version: parquet
    compile (group: 'org.apache.hadoop', name: 'hadoop-client', version: '2.7.3') {
        exclude group: 'org.slf4j', module: 'slf4j-log4j12'
        // Exclude `ASM` because it is binary incompatible with the one which is gotten from `com.conveyal:kryo-tools`: `org.ow2.asm:asm:5.0.4`
        exclude group: 'asm', module: 'asm'
    }
}

// Autoformatting using scalafmt

scalafmt {
    // configFilePath = ".scalafmt.conf" // .scalafmt.conf in the project root is default value, provide only if other location is needed
}


configurations.all {
    resolutionStrategy {
        eachDependency { DependencyResolveDetails dependencyResolveDetails ->
            final requestedDependency = dependencyResolveDetails.requested
            if (requestedDependency.name != 'beam-utilities') {
                force 'javax.media:jai_core:1.1.3'
            }
        }
    }
    exclude group: 'javax.media', module: 'jai_codec'
    exclude group: 'javax.media', module: 'jai_imageio'

}

//compileScala.dependsOn(scalafmtAll)


// Task to run scala tests, as Scala tests not picked up by Gradle by default.
task spec(dependsOn: ['testClasses'], type: JavaExec) {
    main = 'org.scalatest.tools.Runner'
    args = ['-R', 'build/classes/scala/test', '-h', 'build/scalatest-report', '-oD', '-l', 'beam.tags.ExcludeRegular']
    classpath = sourceSets.test.runtimeClasspath
}
build.dependsOn spec

/* //////////////////////////////////////////////////
*  Task to run tagged tests.
*  Note: use space separated list of tags
* ./gradlew taggedTest -Ptags="beam.tags.Performance beam.tags.Integration"
* /////////////////////////////////////////////////// */

task taggedTest(dependsOn: ['testClasses'], type: JavaExec) {
    main = 'org.scalatest.tools.Runner'
    args = ['-R', 'build/classes/scala/test', '-o', '-n'] << (project.findProperty('tags') ?: 'org.scalatest.Ignore')
    classpath = sourceSets.test.runtimeClasspath
}

task specificTest(dependsOn: ['testClasses'], type: JavaExec) {
    main = 'org.scalatest.tools.Runner'
    args = ['-R', 'build/classes/scala/test', '-o', '-s'] << (project.findProperty('suite') ?: 'org.scalatest.Ignore')
    classpath = sourceSets.test.runtimeClasspath
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Task to run tests periodically on continue integration server.
// ./gradlew  periodicTest -Pconfig=test/input/sf-light/sf-light-1k.conf -Piterations=1
////////////////////////////////////////////////////////////////////////////////////////////////////////////
task periodicTest(dependsOn: ['testClasses'], type: JavaExec) {
    main = 'org.scalatest.tools.Runner'
    args = ['-R', 'build/classes/scala/test', '-o', '-n', 'beam.tags.Periodic'] <<
            (project.hasProperty('config') ? '-Dconfig=' + project.findProperty('config') :
                    (project.hasProperty('iterations') ? '-Diterations=' + project.findProperty('iterations') : '')) <<
            (project.hasProperty('config') && project.hasProperty('iterations') ?
                    '-Diterations=' + project.findProperty('iterations') : '')
    jvmArgs = ['-javaagent:build/aspectjweaver-1.8.10.jar']
    classpath = sourceSets.test.runtimeClasspath
    doFirst() {
        if (!project.file('build/aspectjweaver-1.8.10.jar').exists()) {
            download {
                src 'http://central.maven.org/maven2/org/aspectj/aspectjweaver/1.8.10/aspectjweaver-1.8.10.jar'
                dest buildDir
            }
        }
    }
}

//////////////////////////////////////////////////////////////////////
// Amazon WS task to run beam sim on Lambda
//////////////////////////////////////////////////////////////////////

apply plugin: "base"
apply plugin: "jp.classmethod.aws.lambda"

aws {
    profileName = "gradle"
    region = "us-east-2"
}

lambda {
    region = "us-east-2"
}

def getCurrentGitBranch() {
    return grgit.branch.current.name
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Task to run tests periodically on continue integration server.
// ./gradlew deploy -PrunName=sfbay-performance-run -PdeployMode=%% -Pnodes=%%
// ./gradleW deploy -PregionId=us-west-2 -PinstanceType=c5.xlarge -PclusterName=beam-cluster -Pnodes=3
////////////////////////////////////////////////////////////////////////////////////////////////////////////
task deploy {
    def nodesAmount = Integer.valueOf(project.findProperty('nodes') ?: '0')
    def isCluster = nodesAmount > 0
    
    doFirst {
        if (!project.hasProperty('runName')) {
            throw new GradleException('Please name the run by specifying `runName` argument. e.g; ./gradlew deploy -PrunName=sfbay-performance-run')
        }

        switch (project.findProperty('deployMode')) {
            case 'config':
                if (!project.hasProperty('beamConfigs') && !project.hasProperty(getCurrentGitBranch() + '.configs')) {
                    throw new GradleException('beamConfigs is required to deploy config run.')
                }
                break
            case 'experiment':
                if (!project.hasProperty('beamExperiments') && !project.hasProperty(getCurrentGitBranch() + '.experiments')) {
                    throw new GradleException('beamExperiments is required to deploy experement.')
                }
                break
            case 'execute':
                if (!project.hasProperty('executeClass') || !project.hasProperty('executeArgs')) {
                    throw new GradleException('executeClass and executeArgs are required to deploy execute.')
                }
                break
            default:
                if (!isCluster) throw new GradleException('Please provide a valid deployMode.')
                break
        }
    }
    
    def pload

    if (isCluster) {
        pload = """{
    "region": "${project.findProperty('regionId')}",
    "instance_type": "${project.findProperty('instanceType') ?: defaultInstanceType}",
    "creation_tag": "${LocalDateTime.now().format(DateTimeFormatter.ofPattern('yyyy-MM-dd-HH-mm-ss'))}",
    "title": "${project.findProperty('runName') ?: 'beam_EKS_deployment'}",
    "cluster_name": "${project.findProperty('clusterName')}",
    "nodes": "$nodesAmount"
}"""
    } else {
        pload = """{
  "title": "${project.findProperty('runName')}",
  "branch": "${project.findProperty('beamBranch') ?: getCurrentGitBranch()}",
  "commit": "${beamCommit ?: 'HEAD'}",
  "deploy_mode": "${project.findProperty('deployMode')}",
  "configs": "${project.findProperty('beamConfigs') ?: project.findProperty(getCurrentGitBranch() + '.configs')}",
  "experiments": "${
            project.findProperty('beamExperiments') ?: project.findProperty(getCurrentGitBranch() + '.experiments')
        }",
  "execute_class": "${project.findProperty('executeClass')}",
  "execute_args": "${project.findProperty('executeArgs')}",
  "max_ram": "${maxRAM ?: '140g'}",
  "storage_size": ${project.findProperty('storageSize')},
  "batch": "$beamBatch",
  "s3_publish": "${project.findProperty('s3Backup') ?: true}",
  "instance_type": "${project.findProperty('instanceType') ?: defaultInstanceType}",
  "region": "$region",
  "shutdown_wait": "$shutdownWait",
  "shutdown_behaviour": "$shutdownBehaviour",
  "command": "deploy"
}"""
    }

    doLast {
        AWSLambdaPluginExtension ext = getProject().getExtensions().getByType(AWSLambdaPluginExtension.class)
        Field clientConfField = AWSLambdaClient.class.getSuperclass().getDeclaredField("clientConfiguration")
        clientConfField.setAccessible(true)
        AWSLambdaClient lambda = ext.getClient()
        ClientConfiguration cfg = (ClientConfiguration)clientConfField.get(lambda)
        cfg.withSocketTimeout(6*60*1000)
        InvokeRequest request

        if (isCluster) {
            request = new InvokeRequest()
                    .withFunctionName("runNodes")
                    .withInvocationType(InvocationType.RequestResponse)
                    .withLogType(LogType.None)
                    .withPayload(pload)
                    .withSdkClientExecutionTimeout(6*60*1000)
                    .withSdkRequestTimeout(6*60*1000)
        } else {
            request = new InvokeRequest()
                    .withFunctionName("simulateBeam")
                    .withInvocationType(InvocationType.RequestResponse)
                    .withLogType(LogType.None)
                    .withPayload(pload)
        }

        def res = lambda.invoke(request)

        def jsonSlurper = new JsonSlurper()
        def p = jsonSlurper.parseText(new String(res.payload.array(), "UTF-8"))

        def parsed = jsonSlurper.parseText(p.body)

        if (isCluster) {
            configureEKS(parsed)
        }

        println pload
        println new String(res.payload.array(), "UTF-8")
    }
}

def configureEKS(Object parsed) {
    exec {
        executable 'aws'
        args = ["eks", "--region", "us-west-2", "update-kubeconfig", "--name", parsed.cluster, "--role-arn", "arn:aws:iam::340032650202:role/BeamEksDeployment"]
    }
    println parsed.cluster

    def sourceFile = file('kubernetes/default/node-auth.yaml')
    def str = Files.toString(sourceFile, Charsets.UTF_8);
    def replaced = str.replace('{{nodeInstance}}', parsed.NodeInstanceRole)
    Files.write(replaced, file("${project.buildDir}/node-auth.yaml"), Charsets.UTF_8)

    exec {
        executable 'kubectl'
        args = ['apply', '-f', "${project.buildDir}/node-auth.yaml"]
    }
    exec {
        executable 'kubectl'
        args = ['apply', '-f', 'kubernetes/default/secrets.yaml']
    }
    exec {
        executable 'kubectl'
        args = ['apply', '-f', 'kubernetes/default/s3-daemonset.yaml']
    }
    checkTiller()
}

def checkTiller() {
    exec {
        executable 'kubectl'
        args = ['get', 'serviceaccounts', '--namespace', 'kube-system', '-o', 'name']
        standardOutput = new ByteArrayOutputStream()
        ext.accounts = {
            return standardOutput.toString().replace('\n', ' ')
        }
    }
    if (!ext.accounts().contains('tiller')) {
        exec {
            executable 'kubectl'
            args = ['create', 'serviceaccount', '--namespace', 'kube-system', 'tiller']
        }
        exec {
            executable 'kubectl'
            args = ['create', 'clusterrolebinding', 'tiller-cluster-rule', '--clusterrole=cluster-admin', '--serviceaccount=kube-system:tiller']
        }
    }
}

task startEC2(type: AWSLambdaInvokeTask) {
    doFirst {
        if (!project.hasProperty('instanceIds')) {
            throw new GradleException('Please specify instance ids using argument `instanceIds`.')
        }
    }

    def pload = """{
  "instance_ids": "${project.findProperty('instanceIds')}",
  "region": "$region",
  "command": "start"
}"""

    functionName = "ec2StartStop"
    invocationType = InvocationType.RequestResponse
    payload = pload

    doLast {
        println pload
        println new String(invokeResult.payload.array(), "UTF-8")
    }
}

task stopEC2(type: AWSLambdaInvokeTask) {
    doFirst {
        if (!project.hasProperty('instanceIds')) {
            throw new GradleException('Please specify instance ids using argument `instanceIds`.')
        }
    }

    def pload = """{
  "instance_ids": "${project.findProperty('instanceIds')}",
  "region": "$region",
  "command": "${project.hasProperty('terminate') ? "terminate" : "stop"}"
}"""

    functionName = "${project.hasProperty('terminate') ? "simulateBeam" : "ec2StartStop"}"
    invocationType = InvocationType.RequestResponse
    payload = pload

    doLast {
        println pload
        println new String(invokeResult.payload.array(), "UTF-8")
    }
}
//////////////////////////////////////////////////////////////////////
// Generate config classes reflecting the application.conf file
//////////////////////////////////////////////////////////////////////
task generateConfig {
    doLast {
        def tscfgJarFile = project.file('build/tscfg-' + tscfgVersion + '.jar')
        if (!tscfgJarFile.exists() || !tscfgJarFile.isFile()) {
            download {
                src 'https://github.com/carueda/tscfg/releases/download/v' + tscfgVersion + '/tscfg-' + tscfgVersion + '.jar'
                dest buildDir
            }
        }
        javaexec {
            main = "-jar"
            args = [
                    "build/tscfg-${tscfgVersion}.jar",
                    "--spec", "src/main/resources/beam-template.conf",
                    "--scala",
                    "--pn", "beam.sim.config",
                    "--cn", "BeamConfig",
                    "--dd", "src/main/scala/beam/sim/config/"
            ]
        }
    }
}

task repl(type: JavaExec) {
    main = "scala.tools.nsc.MainGenericRunner"
    classpath = sourceSets.main.runtimeClasspath
    standardInput System.in
    args '-usejavacp'
}

task deleteSf {
    doLast {
        if (project.file('production/application-sfbay/r5/network.dat').exists()) {
            delete 'production/application-sfbay/r5/network.dat'
        }
        if (project.file('production/application-sfbay/r5/osm.mapdb').exists()) {
            delete 'production/application-sfbay/r5/osm.mapdb'
        }
        if (project.file('production/application-sfbay/r5/osm.mapdb.p').exists()) {
            delete 'production/application-sfbay/r5/osm.mapdb.p'
        }
    }
}

task sourcesJar(type: Jar, dependsOn: classes) {
    classifier = 'sources'
    from sourceSets.main.allSource
}

docker {
    registryCredentials {
        url = 'https://index.docker.io/v1/'
        username = System.getenv("DOCKER_USER")
        password = System.getenv("DOCKER_PASSWORD")
    }

    javaApplication {
        baseImage = 'anapsix/alpine-java:8u181b13_jdk_unlimited'
        maintainer = 'Kirill Mitin "mitin.kirill.ol@gmail.com"'
        ports = [2552]
        tag = 'beammodel/beam:0.6.2'
    }

    startScripts {
        def configureExec = { line ->
            line = line.replaceAll(~/^exec .*$/) { original ->
                "export HOSTNAME_VALUE=\$(eval \"\$HOSTNAME_COMMAND\")\n" + original
            }
        }

        doLast {
            // Alter the start script for Unix systems.
            unixScript.text =
                    unixScript
                            .readLines()
                            .collect(configureExec)
                            .join('\n')
        }
    }
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Run Via application plugin
// Note: colon preceding "run" is necessary to only run the main project and not launch the GUI as well.
// ./gradlew :run -PappArgs="['--config', 'production/application-sfbay/beam.conf']"
////////////////////////////////////////////////////////////////////////////////////////////////////////////
mainClassName = "beam.sim.RunBeam"


def myAvailableRam = (System.getenv("MAXRAM") ?: (project.findProperty('maxRAM') ?: "140")).toString().replace("g", "").toInteger()


def getCurrentTimestamp = {
    DateTimeFormatter.ofPattern("MM-dd-yyyy_HH-mm-ss")
            .withLocale(Locale.US)
            .withZone(ZoneOffset.UTC)
            .format(Instant.now())
}

def logGC = ["-XX:+PrintGCDetails", "-XX:+PrintGCDateStamps", "-Xloggc:gc_${getCurrentTimestamp()}.log"]

// Use following for remote debug mode
def remoteDebug = ["-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8005"]

def jfr = ["-XX:+UnlockCommercialFeatures", "-XX:+FlightRecorder",
           "-XX:FlightRecorderOptions=defaultrecording=true,disk=true,maxage=10h,dumponexit=true,loglevel=info"]

// On the running machine there should be file /usr/lib/jvm/java-8-oracle/jre/lib/jfr/profile_heap_exception.jfc  with content from
// https://pastebin.com/N3uuUfPz - it's Java Mission Control with metrics about heap allocation and details about exceptions
def jfrWithMem = ["-XX:+UnlockCommercialFeatures", "-XX:+UnlockDiagnosticVMOptions", "-XX:+DebugNonSafepoints",
                  "-XX:StartFlightRecording=delay=2s,duration=60m,name=mem_ex,filename=recording.jfr,settings=profile_heap_exception",
                  "-XX:+FlightRecorder", "-XX:FlightRecorderOptions=disk=true,maxage=10h,dumponexit=true,loglevel=info"]

// UseParallelGC
applicationDefaultJvmArgs = ["-XX:+UseParallelGC", "-XX:+UseParallelOldGC", "-XX:MetaspaceSize=150M", "-Djava.awt.headless=true",
                             "-Dlogback.configurationFile=logback_prod.xml"] + logGC

println(applicationDefaultJvmArgs)

run {
    if (project.hasProperty("appArgs")) {
        args Eval.me(appArgs)
    }

    doFirst() {
        if (!project.file('build/aspectjweaver-1.8.10.jar').exists()) {
            download {
                src 'http://central.maven.org/maven2/org/aspectj/aspectjweaver/1.8.10/aspectjweaver-1.8.10.jar'
                dest buildDir
            }
        }
    }
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Run ExperimentGenerator from Command line
//  gradle :execute -PmainClass=beam.experiment.ExperimentGenerator -PappArgs="['--experiments', 'test/input/beamville/example-experiment/experiment.yml']"
// Run R5 GUI server
//  gradle --stacktrace :execute -PmainClass=com.conveyal.r5.R5Main -PappArgs="['point','--graphs','production/application-sfbay/r5/']"
////////////////////////////////////////////////////////////////////////////////////////////////////////////

task execute(type: JavaExec) {
    jvmArgs = applicationDefaultJvmArgs
    if (project.hasProperty("mainClass")) {
        main = mainClass
    } else {
        main = mainClassName
    }
    classpath = sourceSets.main.runtimeClasspath
    if (project.hasProperty("appArgs")) {
        args Eval.me(appArgs)
    }
    doFirst() {
        if (!project.file('build/aspectjweaver-1.8.10.jar').exists()) {
            download {
                src 'http://central.maven.org/maven2/org/aspectj/aspectjweaver/1.8.10/aspectjweaver-1.8.10.jar'
                dest buildDir
            }
        }
    }
}

task matsimConversion(type: JavaExec) {
    main = 'beam.utils.matsim_conversion.MatsimConversionTool'
    classpath = sourceSets.main.runtimeClasspath
    environment "PWD", "na"
    if (project.hasProperty("confPath")) {
        args Eval.me(confPath)
        // if this triggers an error, try
        // args "${confPath}"
    }
}

task generateDocumentation(type: JavaExec) {
    group 'Documentation'
    description 'Format the data using Sphinx RST formats'

    main = 'beam.docs.GenerateDocumentationTask'
    classpath = sourceSets.main.runtimeClasspath
}

tasks.withType(ScalaCompile) {
    // Enable Scala warnings output
    scalaCompileOptions.additionalParameters = ["-unchecked", "-deprecation", "-feature", "-Xfatal-warnings"]
}

task fmt(dependsOn: scalafmtAll)
task checkScalaFmt() {
    doLast {
        try {
            def workingDir = new File("${project.projectDir}")
            def result = 'git diff --exit-code'.execute(null, workingDir)
            result.waitFor()
            if (result.exitValue() != 0) throw new Exception("""
Please run ./gradlew scalaFmtAll and commit/push the subsequent results to fix this error.
This happened because a git diff yielded a non-zero exit code. 
This task was built to be run on the CI server AFTER scalaFmtAll
It should only error if the results of scalaFmtAll resulted in code modifications.
And that would only happen if the committed code is not formatted as expected.""")
        } catch (e) {
            throw new Exception("An unexpected error was encountered while checking that scalaFmtAll was committed.", e)
        }
    }
}


jar {
    manifest {
        attributes(
                'Built-By': System.properties['user.name'],
                'Build-Timestamp': new java.text.SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSZ").format(new Date()),
                'Created-By': "Gradle ${gradle.gradleVersion}",
                'Build-Jdk': "${System.properties['java.version']} (${System.properties['java.vendor']} ${System.properties['java.vm.version']})",
                'Build-OS': "${System.properties['os.name']} ${System.properties['os.arch']} ${System.properties['os.version']}",
                'Specification-Title': "Java Advanced Imaging Image I/O Tools",
                'Specification-Version': "1.1",
                'Specification-Vendor': "Sun Microsystems, Inc.",
                'Implementation-Title': "com.sun.media.imageio",
                'Implementation-Version': "1.1",
                'Implementation-Vendor': "Sun Microsystems, Inc.",
                'Build-Commit': "${grgit.head().id}",
                'Build-Branch': "${grgit.branch.current.name}"
        )
    }
}

shadowJar {
    transform(com.github.jengelman.gradle.plugins.shadow.transformers.AppendingTransformer) {
        resource = 'reference.conf'
    }
    mergeServiceFiles()
}

helm {
    home = file("${project.buildDir}/helm")
    debug = true

    def dateCreation = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd-HH-mm-ss"))

    filtering {
        values.put 'beamImage', 'beammodel/beam'
        values.put 'beamImageTag', '0.6.2'
        values.put 'bucketName', 'beam-config'
        values.put 'authorName', 'Kirill Mitin'
        values.put 'authorEmail', 'mitin.kirill.ol@gmail.com'
        values.put 'creationTime', dateCreation
        values.put 'simulationConfig', "${project.findProperty('config')}"
        values.put 'mem', "${project.findProperty('mem')}"
        values.put 'cpu', "${project.findProperty('cpu')}"
    }
    lint {
        strict = true
    }

    charts {
        common {
            chartName = 'beam-common'
            chartVersion = '0.1.0'
            sourceDir = file('kubernetes/beam-common')
        }

        standalone {
            chartName = 'beam-standalone'
            chartVersion = '0.1.0'
            sourceDir = file('kubernetes/beam-standalone')

            filtering {
                values.put 'simulationNamespace', "standalone-${dateCreation}"
            }

            dependencies {
                add(name: 'common', chart: 'beam-common')
            }

        }

        cluster {
            chartName = 'beam-cluster'
            chartVersion = '0.1.0'
            sourceDir = file('kubernetes/beam-cluster')

            filtering {
                values.put 'simulationNamespace', "cluster-${dateCreation}"
            }

            dependencies {
                add(name: 'common', chart: 'common')
            }
        }
    }

    releases {
        standalone {
            from charts.standalone
            replace = true
        }
        cluster {
            from charts.cluster
            replace = true
        }
    }
}

task helmInit(type: HelmInit) {
    upgrade = true
    doLast {
        exec {
            executable 'kubectl'
            args = ['patch', 'deploy', '--namespace', 'kube-system', 'tiller-deploy', '-p', '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}']
        }
    }
}

helmInit.dependsOn clean

helmUpdateStandaloneChartDependencies.dependsOn helmPackageCommonChart

task deployStandaloneChart(dependsOn: [helmPackageStandaloneChart, helmPackageCommonChart, helmInit], type: HelmInstall) {
    def date = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd-HH-mm-ss"))
    chart = "${project.buildDir}/helm/charts/beam-standalone-0.1.0.tgz"
    releaseName = "beam-standalone-${date}"
}

task helmStandaloneList(dependsOn: [helmInit], type: Exec) {
    executable 'helm'
    args 'ls', '-q', 'beam-standalone'
    standardOutput = new ByteArrayOutputStream()
    ext.charts = {
        return standardOutput.toString().replace('\n', ' ')
    }
}

task removeStandaloneCharts(dependsOn: [helmStandaloneList]) {
    doLast {
        exec {
            def charts = Arrays.asList(helmStandaloneList.charts().trim().split(' '))
            executable 'helm'
            def argList =  ["delete", "--purge"] + charts
            args = argList
        }
    }
}
helmUpdateClusterChartDependencies.dependsOn helmPackageCommonChart

task deployClusterChart(dependsOn: [helmPackageCommonChart, helmPackageClusterChart, helmInit], type: HelmInstall) {
    def date = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd-HH-mm-ss"));
    chart = "${project.buildDir}/helm/charts/beam-cluster-0.1.0.tgz"
    releaseName = "beam-cluster-${date}"
}

task helmClusterList(dependsOn: [helmInit], type: Exec) {
    executable 'helm'
    args 'ls', '-q', 'beam-cluster'
    standardOutput = new ByteArrayOutputStream()
    ext.charts = {
        return standardOutput.toString().replace('\n', ' ')
    }
}

task removeClusterCharts(dependsOn: [helmClusterList]) {
    doLast {
        exec {
            def charts = Arrays.asList(helmClusterList.charts().trim().split(' '))
            executable 'helm'
            def argList =  ["delete", "--purge"] + charts
            args = argList
        }
    }
}

task initEksCreation(type: AWSLambdaInvokeTask) {
    def date = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd-HH-mm-ss"))
    functionName = "eksCreation"
    invocationType = InvocationType.Event
    def pload = """{
    "region": "${project.findProperty('regionId')}",
    "instance_id": "${project.findProperty('instanceType') ?: defaultInstanceType}",
    "creation_tag": "${date}"
}"""
    payload = pload
    ext.creation = date
    doLast {
        println date
    }
}

task createEKSCluster(dependsOn: initEksCreation) {
    def pload = """{
    "region": "${project.findProperty('regionId')}",
    "creation_tag": "${initEksCreation.creation}"
    }"""

    doLast {
        def parsed

        while (!parsed) {
            sleep(5 * 1000)
            AWSLambdaPluginExtension ext = getProject().getExtensions().getByType(AWSLambdaPluginExtension.class)
            AWSLambda lambda = ext.getClient()
            InvokeRequest request = new InvokeRequest()
                    .withFunctionName("eksDescribe")
                    .withInvocationType(InvocationType.RequestResponse)
                    .withLogType(LogType.None)

            request.setPayload(pload)
            def res = lambda.invoke(request)

            def jsonSlurper = new JsonSlurper()
            def p = jsonSlurper.parseText(new String(res.payload.array(), "UTF-8"))

            parsed = jsonSlurper.parseText(p.body)
        }

        println parsed.cluster
    }
}
